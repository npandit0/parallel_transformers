{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20359b8e",
   "metadata": {},
   "source": [
    "# Model generation without the kv cache\n",
    "\n",
    "Let's see if we can get the code to work with turning the kv cache off.\n",
    "\n",
    "How the eigenvaleus be so large if you are using layer norm? In fact, the evals are large BECAUSE we are using RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4313c140-421d-4f1f-a283-3461b8db70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "from functools import partial\n",
    "from equinox._misc import default_floating_dtype\n",
    "from jaxtyping import Array, Float, Scalar\n",
    "from typing import Optional, Tuple, List, NamedTuple\n",
    "\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a7657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672df14d-d052-403a-8b68-b94a6240abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CPU for torch\n",
    "device  = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7533de2e-9d14-411a-a55a-852cb62646c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_21551/2163712912.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "# Load the model dict, and check if any GPU is used\n",
    "# state_dict = torch.load(\"mistral-7B-v0.1/consolidated.00.pth\")\n",
    "# why is this so much faster on our computer??\n",
    "state_dict = torch.load(\n",
    "    \"/Users/xaviergonzalez/Desktop/xavier_folders/stanford/cs229s/mistral_jax/model_files/consolidated.00.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27c428-fd21-41a1-9a5c-99a966f5a2a3",
   "metadata": {},
   "source": [
    "# 1. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd26d27d-8e7e-46e9-ba8d-187a8a57a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self._model = SentencePieceProcessor(model_file=model_path)\n",
    "\n",
    "    @property\n",
    "    def eos_id(self) -> int:\n",
    "        return self._model.eos_id()\n",
    "\n",
    "    @property\n",
    "    def pad_id(self) -> int:\n",
    "        return self._model.pad_id()\n",
    "\n",
    "    def encode(self, s: str) -> List[int]:\n",
    "        return [self._model.bos_id(), *self._model.encode(s)]\n",
    "\n",
    "    def decode(self, t: List[int]) -> str:\n",
    "        return self._model.decode(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5aced-2da9-42df-900d-b9d11d5f45fa",
   "metadata": {},
   "source": [
    "# 2. RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431e5fa1-25dd-401a-abfb-1371f5f1b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_frequencies(dim, max_pos, theta=10000.0):\n",
    "    inv_freq = 1.0 / (\n",
    "        theta ** (jnp.arange(0, dim, 2, dtype=jnp.float32)[: (dim // 2)] / dim)\n",
    "    )\n",
    "    t = jnp.arange(0, max_pos, dtype=jnp.float32)\n",
    "    freqs = jnp.outer(t, inv_freq)\n",
    "    return jnp.cos(freqs), jnp.sin(freqs)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3,))\n",
    "def calculate_rope(x, cos_freq, sin_freq, offset=0):\n",
    "    # x shape  is [seqlen, num_heads, heads_dim]\n",
    "\n",
    "    # Get the sequence length\n",
    "    seqlen = x.shape[0]\n",
    "\n",
    "    # Get the corresponding positional embeddings\n",
    "    sin = sin_freq[offset : offset + seqlen, :]\n",
    "    cos = cos_freq[offset : offset + seqlen, :]\n",
    "\n",
    "    # Positional embeddings are 2D while our input is 3D\n",
    "    # if `num_heads` dimension is present in the inputs.\n",
    "    # We need to add another dimension to our positional embeddings\n",
    "    sin = sin[:, jnp.newaxis, :]\n",
    "    cos = cos[:, jnp.newaxis, :]\n",
    "\n",
    "    # Get the even-odd positions from the inputs\n",
    "    x1 = x[..., 0::2]\n",
    "    x2 = x[..., 1::2]\n",
    "\n",
    "    # Matmul with the rotation matrix\n",
    "    # [cos_nθ, -sin_nθ] [x1]\n",
    "    # [sin_nθ,  cos_nθ] [x2]\n",
    "    # => [x1 * cos_nθ - x2 * sin_nθ, x1 * sin_nθ + x2 * cos_nθ]\n",
    "    pos_embed = jnp.stack([x1 * cos - x2 * sin, x1 * sin + x2 * cos], axis=-1)\n",
    "    pos_embed = jax.lax.collapse(pos_embed, -2)\n",
    "    return pos_embed.astype(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1aa31-614e-4483-8599-c5f0b4623292",
   "metadata": {},
   "source": [
    "# 3. RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fbb2d-ce6f-4b1a-a198-e4f37fab93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(eqx.Module):\n",
    "    \"\"\"\n",
    "    Make the root mean square of the output to be 1.\n",
    "    \"\"\"\n",
    "    eps: float\n",
    "    weight: Float[Array, \"*shape\"]\n",
    "\n",
    "    def __init__(self, dim, eps, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        self.eps = eps\n",
    "        self.weight = jnp.ones(shape=dim, dtype=dtype)\n",
    "\n",
    "    def rmsnorm(self, x):\n",
    "        return jnp.sqrt(jnp.mean(x**2, keepdims=True) + self.eps)\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * jax.lax.rsqrt(jnp.mean(x **2 , keepdims=True) + self.eps)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = self._norm(x.astype(jnp.float32)).astype(x.dtype)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f9a21-bb3c-45e8-805c-5f8605f72423",
   "metadata": {},
   "source": [
    "# 4. FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efffa74f-556b-4c3e-9f73-e23acfa1da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(eqx.Module):\n",
    "    w1: eqx.nn.Linear\n",
    "    w2: eqx.nn.Linear\n",
    "    w3: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "        self.w1 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.w2 = eqx.nn.Linear(args.hidden_dim, args.dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.w3 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = jax.nn.silu(self.w1(x).astype(jnp.float32)).astype(x.dtype)\n",
    "        return self.w2(h * self.w3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c459d5-b30d-48e5-924b-ea661542e8a2",
   "metadata": {},
   "source": [
    "# 5. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2048b724-3015-43c8-be5e-0214eb83af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    head_dim: int\n",
    "    n_kv_heads: int\n",
    "    kv_repeats: int\n",
    "    sliding_window: int\n",
    "    scale: float\n",
    "    wq: eqx.nn.Linear\n",
    "    wk: eqx.nn.Linear\n",
    "    wv: eqx.nn.Linear\n",
    "    wo: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.head_dim\n",
    "        self.n_kv_heads = args.n_kv_heads\n",
    "        self.dim = args.dim\n",
    "        self.kv_repeats = self.n_heads // self.n_kv_heads\n",
    "        self.sliding_window = args.sliding_window\n",
    "\n",
    "        self.scale = args.head_dim**-0.5\n",
    "\n",
    "        self.wq = eqx.nn.Linear(args.dim, args.n_heads * args.head_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.wk = eqx.nn.Linear(args.dim, args.n_kv_heads * args.head_dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.wv = eqx.nn.Linear(args.dim, args.n_kv_heads * args.head_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "        self.wo = eqx.nn.Linear(args.n_heads * args.head_dim, args.dim, use_bias=False, key=key4, dtype=dtype)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(2, 3))\n",
    "    def get_cache_slice(self, x, pos, kv_repeats):\n",
    "        x_slice = x.at[:pos, :, :].get()\n",
    "        x_slice = jnp.repeat(x_slice, kv_repeats, axis=1)\n",
    "        return x_slice\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_qkv(self, x):\n",
    "        seqlen, _ = x.shape\n",
    "\n",
    "        xq = jax.vmap(self.wq)(x)\n",
    "        xk = jax.vmap(self.wk)(x)\n",
    "        xv = jax.vmap(self.wv)(x)\n",
    "\n",
    "        xq = jnp.reshape(xq, (seqlen, self.n_heads, self.head_dim))\n",
    "        xk = jnp.reshape(xk, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        xv = jnp.reshape(xv, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        return xq, xk, xv\n",
    "\n",
    "    @jax.jit\n",
    "    def update_cache_values(self, xk, xv, cache_k, cache_v, positions):\n",
    "        cache_k = cache_k.at[positions, ...].set(xk[positions, ...])\n",
    "        cache_v = cache_v.at[positions, ...].set(xv[positions, ...])\n",
    "        return cache_k, cache_v\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def prefill(self, xk, xv):\n",
    "        key = jnp.repeat(xk, self.kv_repeats, axis=1)\n",
    "        value = jnp.repeat(xv, self.kv_repeats, axis=1)\n",
    "        return key, value\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_scores_and_output(self, xq, key, value, mask, seqlen):\n",
    "        query = jnp.transpose(xq, (1, 0, 2))\n",
    "        key = jnp.transpose(key, (1, 0, 2))\n",
    "        value = jnp.transpose(value, (1, 0, 2))\n",
    "\n",
    "        # # # scores : [n_heads, seqlen | 1, seqlen]\n",
    "        scores = jnp.matmul(query, jnp.transpose(key, (0, 2, 1))) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            # Mask will of shape [seqlen, seqlen] but our scores\n",
    "            # have shape [num_heads, seqlen, seqlen], hence we need\n",
    "            # to introduce another dimension in the mask\n",
    "            mask = mask[jnp.newaxis, ...]\n",
    "            scores = scores + mask\n",
    "\n",
    "        scores = jax.nn.softmax(scores.astype(jnp.float32), axis=-1).astype(query.dtype)\n",
    "        output = jnp.matmul(scores, value)\n",
    "        output = jnp.reshape(jnp.transpose(output, (1, 0, 2)), (seqlen, -1))\n",
    "        output = jax.vmap(self.wo)(output)\n",
    "        return output\n",
    "\n",
    "    def __call__(self,  x, cos_freq, sin_freq, positions, mask=None, cache_k=None, cache_v=None):\n",
    "        # x shape: [seqlen, embed_dim]\n",
    "        seqlen, _ = x.shape\n",
    "        # 1. Calculate qkv\n",
    "        xq, xk, xv = self.compute_qkv(x)\n",
    "\n",
    "        # 2. Calculate RoPE\n",
    "        xq = calculate_rope(xq, cos_freq, sin_freq, 0)\n",
    "        xk = calculate_rope(xk, cos_freq, sin_freq, 0)\n",
    "\n",
    "        key, value = self.prefill(xk, xv)\n",
    "\n",
    "        # # 3. Update cache\n",
    "        # cache_k, cache_v = self.update_cache_values(xk, xv, cache_k, cache_v, positions)\n",
    "\n",
    "        # # 4. Generation\n",
    "        # if positions.shape[0] > 1:\n",
    "        #     # prefill\n",
    "        #     key, value = self.prefill(xk, xv)\n",
    "        # else:\n",
    "        #     # single-token generation\n",
    "        #     cur_pos = positions[-1].item() + 1\n",
    "        #     key = self.get_cache_slice(cache_k, cur_pos, self.kv_repeats)\n",
    "        #     value = self.get_cache_slice(cache_v, cur_pos, self.kv_repeats)\n",
    "\n",
    "        # 5. Output\n",
    "        output = self.compute_scores_and_output(xq, key, value, mask, seqlen)\n",
    "        # return output, cache_k, cache_v\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a123d-c4b1-44f0-a6cd-5daf67c63adb",
   "metadata": {},
   "source": [
    "# 6. TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84cb56f-1a8f-4c28-9f3e-2c180f5e86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    attention: Attention\n",
    "    attention_norm: RMSNorm\n",
    "    feed_forward: FeedForward\n",
    "    ffn_norm: RMSNorm\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "\n",
    "        self.attention = Attention(args, key=key1, dtype=dtype)\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "        self.feed_forward = FeedForward(args, key=key2, dtype=dtype)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "    # def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask):\n",
    "        normed_x = jax.vmap(self.attention_norm)(x)\n",
    "        # r, cache_k, cache_v = self.attention(normed_x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\n",
    "        r = self.attention(\n",
    "            normed_x, cos_freq, sin_freq, positions, mask\n",
    "        )\n",
    "        h = x + r\n",
    "        r = jax.vmap(self.feed_forward)(jax.vmap(self.ffn_norm)(h))\n",
    "        out = h + r\n",
    "        return out\n",
    "        # return out, cache_k, cache_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f9502-010b-42ca-86ac-666e9476ff5c",
   "metadata": {},
   "source": [
    "# 7. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdec9a64-57c4-4fb5-8e8a-c3ecb4e5bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(eqx.Module):\n",
    "    tok_embeddings: eqx.nn.Embedding\n",
    "    layers: TransformerBlock\n",
    "    norm: RMSNorm\n",
    "    output: eqx.nn.Linear\n",
    "    vocab_size: int\n",
    "    n_layers: int\n",
    "    sliding_window: int\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        self.sliding_window = args.sliding_window\n",
    "        keys = jax.random.split(key, args.n_layers + 2)\n",
    "        embed_key, linear_key, tf_layers_keys = keys[0], keys[1], keys[2:]\n",
    "\n",
    "        self.tok_embeddings = eqx.nn.Embedding(args.vocab_size, args.dim, key=embed_key, dtype=dtype)\n",
    "        self.norm = RMSNorm(dim=args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "        self.output = eqx.nn.Linear(args.dim, args.vocab_size, use_bias=False, key=linear_key, dtype=dtype)\n",
    "        self.layers = [TransformerBlock(args, key=tf_layers_keys[i], dtype=dtype) for i in range(args.n_layers)] \n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_embeddings(self, x):\n",
    "        return jax.vmap(self.tok_embeddings)(x)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_mask(self, seqlen):\n",
    "        t = jnp.full((seqlen, seqlen), dtype=jnp.bfloat16, fill_value=1)\n",
    "        mask = jnp.tril(t, k=0)\n",
    "        # make the mask banded to account for sliding window\n",
    "        mask = jnp.triu(mask, k=-self.sliding_window)\n",
    "        mask = jnp.log(mask)\n",
    "        return mask\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_norm(self, x):\n",
    "        return jax.vmap(self.norm)(x)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_output(self, x):\n",
    "        return jax.vmap(self.output)(x)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(1,))\n",
    "    def update_cache_values(self, idx, cache_k, cache_v, cache_k_updates, cache_v_updates):\n",
    "        cache_k = cache_k.at[idx, :, :, :].set(cache_k_updates)\n",
    "        cache_v = cache_v.at[idx, :, :, :].set(cache_v_updates)\n",
    "        return cache_k, cache_v\n",
    "\n",
    "    # def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "    #     # x is of shape (seqlen, )\n",
    "    #     h = self.compute_embeddings(x)\n",
    "\n",
    "    #     if x.shape[-1] > 1:\n",
    "    #         seqlen = x.shape[-1]\n",
    "    #         mask = self.compute_mask(seqlen)\n",
    "    #     else:\n",
    "    #         mask = None\n",
    "\n",
    "    #     # the for loop!!!\n",
    "\n",
    "    #     for i, layer in enumerate(self.layers):\n",
    "    #         #pdb.set_trace()\n",
    "    #         # h has shape (len(positions), dim)\n",
    "    #         # cache_ki has shape (sliding_window_len, head_dim, n_kv_heads)\n",
    "    #         h, cache_ki, cache_vi = layer(h, cos_freq, sin_freq, positions, mask, cache_k[i, ...], cache_v[i, ...]) # I think we could get away with creating blank entries for h, cache_ki, and cache_vi\n",
    "    #         # pdb.set_trace()\n",
    "    #         cache_k, cache_v = self.update_cache_values(i, cache_k, cache_v, cache_ki, cache_vi) # I think all this line is doing is plugging in cache_ki and cache_vi in the appropriate palce\n",
    "\n",
    "    #     h = self.compute_norm(h)\n",
    "    #     h = self.compute_output(h).astype(jnp.float32)\n",
    "    #     return h, cache_k, cache_v\n",
    "\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask):\n",
    "        \"\"\"\n",
    "        Edited to do prefilling instead of kv cache\n",
    "        \"\"\"\n",
    "        # x is of shape (seqlen, )\n",
    "        h = self.compute_embeddings(x)\n",
    "\n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        all_states = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # h has shape (len(positions), dim)\n",
    "            # cache_ki has shape (sliding_window_len, head_dim, n_kv_heads)\n",
    "            h = layer(h, cos_freq, sin_freq, positions, mask) # h has shape (T,D)\n",
    "            all_states.append(h)\n",
    "            # print(f\"at layer {i}, the shape of the feature is {h.shape}\")\n",
    "\n",
    "        # h = self.compute_norm(h)\n",
    "        # h = self.compute_output(h).astype(jnp.float32)\n",
    "        return jnp.array(all_states)\n",
    "\n",
    "    def partial_layers(self, layers, cos_freq, sin_freq, positions, mask):\n",
    "        \"\"\"\n",
    "        Ideally we could use jtu instead...\n",
    "        \"\"\"\n",
    "        def partial_layer(layer):\n",
    "            return partial(layer.__call__, cos_freq=cos_freq, sin_freq=sin_freq, positions=positions, mask=mask)\n",
    "\n",
    "        return [partial_layer(layer) for layer in layers] # really would prefer not to use list comprehension\n",
    "\n",
    "    def parallel_call(self, x, cos_freq, sin_freq, positions, mask, num_iters=7):\n",
    "        \"\"\"\n",
    "        Should give the same output as call, but using fixed point iterations\n",
    "        \"\"\"\n",
    "        h0 = self.compute_embeddings(x)\n",
    "        T, D = h0.shape\n",
    "\n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        # parallel logic\n",
    "        num_layers = len(self.layers)\n",
    "        # pdb.set_trace()\n",
    "        partialed_layers = self.partial_layers(self.layers, cos_freq, sin_freq, positions, mask)\n",
    "        states_guess = [\n",
    "            jnp.ones((T, D)) for _ in range(num_layers)\n",
    "        ]  # make sure to stay near rms norm equal to 1\n",
    "        # states_guess = [jnp.zeros((T, D)) for _ in range(num_layers)] # never do this when using rms norm, grads will explode\n",
    "        # calls out to deer\n",
    "        all_states = deer(h0, partialed_layers, states_guess, num_iters) # (batch_size, num_iters, num_layers, T, D)\n",
    "\n",
    "        return jnp.array(all_states)\n",
    "        # h = all_states[-1][-1]\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        # h = self.compute_norm(h)\n",
    "        # h = self.compute_output(h).astype(jnp.float32)\n",
    "        # return h\n",
    "\n",
    "\n",
    "def deer(x, layers, states_guess, num_iters, k =1):\n",
    "    \"\"\"\n",
    "    runs deer (fiddly logic in the rearrange)\n",
    "\n",
    "    Args:\n",
    "      x: (T, d) initial inputs to transformer stack\n",
    "      layers: list of TransformerLayer objects (the functions that propagate information over the stack)\n",
    "      states_guess: list of length num_layers of (T, D) shaped arrays; this is the initial guess for the states. don't make them all zero!\n",
    "      num_iters: number of iterations to run for\n",
    "      k: damping factor\n",
    "    \"\"\"\n",
    "    T, D = x.shape\n",
    "    num_layers = len(layers)\n",
    "\n",
    "    @jax.vmap\n",
    "    def binary_op(q_i, q_j):\n",
    "        \"\"\"Binary operator for parallel scan of linear recurrence. Assumes a full Jacobian matrix A\n",
    "        Args:\n",
    "            q_i: tuple containing J_i and b_i at position i       (P,P), (P,)\n",
    "            q_j: tuple containing J_j and b_j at position j       (P,P), (P,)\n",
    "        Returns:\n",
    "            new element ( A_out, Bu_out )\n",
    "        \"\"\"\n",
    "        A_i, b_i = q_i\n",
    "        A_j, b_j = q_j\n",
    "        return A_j @ A_i, A_j @ b_i + b_j\n",
    "\n",
    "    def step(states, args):\n",
    "        \"\"\"\n",
    "        This step is a single deer iteration (will eventually be sequential scanned)\n",
    "        Args:\n",
    "          states: list of length num_layers of (T, D) shaped arrays\n",
    "          args: None\n",
    "        \"\"\"\n",
    "        states = [x] + states[:-1]  # length num_layers\n",
    "        print(f\"states shape is {states[0].shape}\")\n",
    "        fs = jnp.array(\n",
    "            jtu.tree_map(lambda x, f: f(x), states, layers)\n",
    "        )  # (num_layers, T,D) arrays, note that we keep states as a list so we can use jtu.tree_map\n",
    "        print(f\"fs shape is {fs.shape}\")\n",
    "        As = jnp.array(\n",
    "            jtu.tree_map(lambda x, f: jax.jacrev(f)(x), states, layers) # this line seems to be the bottleneck, but that's odd bc we'd expect someone to take this grads during backprop\n",
    "        )  # (num_layers, T, D, T, D) tensors\n",
    "        print(f\"As shape is {As.shape}\")\n",
    "        As = As.at[0].set(jnp.zeros((T, D, T, D)))\n",
    "        # pdb.set_trace()\n",
    "        # need to make the first A equal to zero\n",
    "        states = jnp.array(states)  # (num_layers, T,D)\n",
    "        # do some rearranging\n",
    "        print(\"starting the rearranges\")\n",
    "        flattened_states = jnp.reshape(states, (num_layers, T * D))  # (num_layers, T*D)\n",
    "        flattened_As = jnp.reshape(\n",
    "            As, (num_layers, T * D, T * D)\n",
    "        )  # (num_layers, T*D, T*D)\n",
    "        # somehow, we aren't even getting here\n",
    "        # print(\"we are about to start computing eigenvalues\")\n",
    "        # for A in flattened_As:\n",
    "        #     print(jnp.linalg.eigvals(A))\n",
    "        # pdb.set_trace()\n",
    "        flattened_fs = jnp.reshape(fs, (num_layers, T * D))  # (num_layers, T*D)\n",
    "        bs = flattened_fs - jnp.einsum(\n",
    "            \"tij,tj->ti\", flattened_As, flattened_states\n",
    "        )  # (num_layers, T*D)\n",
    "\n",
    "        # finally ready to evaluate linearized dynamics (in parallel)\n",
    "        print(\"we are about to start the associative scan\")\n",
    "        _, new_states = jax.lax.associative_scan(\n",
    "            binary_op, (flattened_As, bs)\n",
    "        )  # parallel operation\n",
    "        # new_states = jnp.nan_to_num(new_states)  # zero out nans, (num_layers, T*D)\n",
    "        new_states = jnp.reshape(new_states, (num_layers, T, D))  # (num_layers, T, D)\n",
    "        return list(new_states), new_states\n",
    "\n",
    "    print(\"starting deer outer loop\")\n",
    "    # states_guess, iter_hist = jax.lax.scan(\n",
    "    #     step, states_guess, None, length=num_iters\n",
    "    # )  # state_iters will show all the intermediate traces\n",
    "\n",
    "    iter_hist = []\n",
    "    for i in range(num_iters):\n",
    "        print()\n",
    "        print(\"-----------------\")\n",
    "        print(f\"iteration {i}\")\n",
    "        print(\"-----------------\")\n",
    "        print()\n",
    "        states_guess, iter_hist_add = step(states_guess, None)\n",
    "        iter_hist.append(iter_hist_add)\n",
    "\n",
    "    # return states_guess\n",
    "    return jnp.array(iter_hist) # (num_iters, num_layers, T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5a7c63f-4be6-4bad-b6f5-b77c77bcc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArgs(NamedTuple):\n",
    "    dim: int\n",
    "    n_layers: int\n",
    "    n_heads: int\n",
    "    n_kv_heads: int\n",
    "    head_dim: int\n",
    "    hidden_dim: int\n",
    "    vocab_size: int\n",
    "    sliding_window: int\n",
    "    norm_eps: float\n",
    "    max_batch_size: int = 1\n",
    "\n",
    "# maybe we could do a proto_params.json, and just not load in the weights\n",
    "with open(\n",
    "    \"/Users/xaviergonzalez/Desktop/xavier_folders/stanford/cs229s/mistral_jax/model_files/params.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    #with open('./mistral-7B-v0.1/params.json', 'r') as f:\n",
    "    args = ModelArgs(**json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a2d2cf-40f6-48af-a70f-37847532e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_weights_from_torch(torch_weights, eqx_model):\n",
    "    def load_weights(path, leaf):\n",
    "        path_pieces = []\n",
    "        for path_elem in path:\n",
    "            if isinstance(path_elem, jax.tree_util.GetAttrKey):\n",
    "                 path_pieces.append(path_elem.name)\n",
    "            elif isinstance(path_elem, jax.tree_util.SequenceKey):\n",
    "                 path_pieces.append(str(path_elem.idx))\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported path type {type(path_elem)}\")\n",
    "\n",
    "        path_pieces = \".\".join(path_pieces)\n",
    "        \n",
    "        if \"weight\" in path_pieces:\n",
    "            weight = torch_weights[path_pieces]\n",
    "            weight = jnp.asarray(weight.float().numpy(), dtype=jnp.bfloat16)\n",
    "            assert weight.shape == leaf.shape\n",
    "            assert weight.dtype == leaf.dtype\n",
    "            return weight\n",
    "        else:\n",
    "            print(f\"Weights not ported for: {path_pieces}\")\n",
    "            return leaf\n",
    "\n",
    "    return jax.tree_util.tree_map_with_path(load_weights, eqx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67530c78-98a9-4f84-aa4b-af0819b5f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights not ported for: layers.0.dim\n",
      "Weights not ported for: layers.0.n_heads\n",
      "Weights not ported for: layers.0.attention.dim\n",
      "Weights not ported for: layers.0.attention.n_heads\n",
      "Weights not ported for: layers.0.attention.head_dim\n",
      "Weights not ported for: layers.0.attention.n_kv_heads\n",
      "Weights not ported for: layers.0.attention.kv_repeats\n",
      "Weights not ported for: layers.0.attention.sliding_window\n",
      "Weights not ported for: layers.0.attention.scale\n",
      "Weights not ported for: layers.0.attention_norm.eps\n",
      "Weights not ported for: layers.0.ffn_norm.eps\n",
      "Weights not ported for: layers.1.dim\n",
      "Weights not ported for: layers.1.n_heads\n",
      "Weights not ported for: layers.1.attention.dim\n",
      "Weights not ported for: layers.1.attention.n_heads\n",
      "Weights not ported for: layers.1.attention.head_dim\n",
      "Weights not ported for: layers.1.attention.n_kv_heads\n",
      "Weights not ported for: layers.1.attention.kv_repeats\n",
      "Weights not ported for: layers.1.attention.sliding_window\n",
      "Weights not ported for: layers.1.attention.scale\n",
      "Weights not ported for: layers.1.attention_norm.eps\n",
      "Weights not ported for: layers.1.ffn_norm.eps\n",
      "Weights not ported for: layers.2.dim\n",
      "Weights not ported for: layers.2.n_heads\n",
      "Weights not ported for: layers.2.attention.dim\n",
      "Weights not ported for: layers.2.attention.n_heads\n",
      "Weights not ported for: layers.2.attention.head_dim\n",
      "Weights not ported for: layers.2.attention.n_kv_heads\n",
      "Weights not ported for: layers.2.attention.kv_repeats\n",
      "Weights not ported for: layers.2.attention.sliding_window\n",
      "Weights not ported for: layers.2.attention.scale\n",
      "Weights not ported for: layers.2.attention_norm.eps\n",
      "Weights not ported for: layers.2.ffn_norm.eps\n",
      "Weights not ported for: layers.3.dim\n",
      "Weights not ported for: layers.3.n_heads\n",
      "Weights not ported for: layers.3.attention.dim\n",
      "Weights not ported for: layers.3.attention.n_heads\n",
      "Weights not ported for: layers.3.attention.head_dim\n",
      "Weights not ported for: layers.3.attention.n_kv_heads\n",
      "Weights not ported for: layers.3.attention.kv_repeats\n",
      "Weights not ported for: layers.3.attention.sliding_window\n",
      "Weights not ported for: layers.3.attention.scale\n",
      "Weights not ported for: layers.3.attention_norm.eps\n",
      "Weights not ported for: layers.3.ffn_norm.eps\n",
      "Weights not ported for: layers.4.dim\n",
      "Weights not ported for: layers.4.n_heads\n",
      "Weights not ported for: layers.4.attention.dim\n",
      "Weights not ported for: layers.4.attention.n_heads\n",
      "Weights not ported for: layers.4.attention.head_dim\n",
      "Weights not ported for: layers.4.attention.n_kv_heads\n",
      "Weights not ported for: layers.4.attention.kv_repeats\n",
      "Weights not ported for: layers.4.attention.sliding_window\n",
      "Weights not ported for: layers.4.attention.scale\n",
      "Weights not ported for: layers.4.attention_norm.eps\n",
      "Weights not ported for: layers.4.ffn_norm.eps\n",
      "Weights not ported for: layers.5.dim\n",
      "Weights not ported for: layers.5.n_heads\n",
      "Weights not ported for: layers.5.attention.dim\n",
      "Weights not ported for: layers.5.attention.n_heads\n",
      "Weights not ported for: layers.5.attention.head_dim\n",
      "Weights not ported for: layers.5.attention.n_kv_heads\n",
      "Weights not ported for: layers.5.attention.kv_repeats\n",
      "Weights not ported for: layers.5.attention.sliding_window\n",
      "Weights not ported for: layers.5.attention.scale\n",
      "Weights not ported for: layers.5.attention_norm.eps\n",
      "Weights not ported for: layers.5.ffn_norm.eps\n",
      "Weights not ported for: layers.6.dim\n",
      "Weights not ported for: layers.6.n_heads\n",
      "Weights not ported for: layers.6.attention.dim\n",
      "Weights not ported for: layers.6.attention.n_heads\n",
      "Weights not ported for: layers.6.attention.head_dim\n",
      "Weights not ported for: layers.6.attention.n_kv_heads\n",
      "Weights not ported for: layers.6.attention.kv_repeats\n",
      "Weights not ported for: layers.6.attention.sliding_window\n",
      "Weights not ported for: layers.6.attention.scale\n",
      "Weights not ported for: layers.6.attention_norm.eps\n",
      "Weights not ported for: layers.6.ffn_norm.eps\n",
      "Weights not ported for: layers.7.dim\n",
      "Weights not ported for: layers.7.n_heads\n",
      "Weights not ported for: layers.7.attention.dim\n",
      "Weights not ported for: layers.7.attention.n_heads\n",
      "Weights not ported for: layers.7.attention.head_dim\n",
      "Weights not ported for: layers.7.attention.n_kv_heads\n",
      "Weights not ported for: layers.7.attention.kv_repeats\n",
      "Weights not ported for: layers.7.attention.sliding_window\n",
      "Weights not ported for: layers.7.attention.scale\n",
      "Weights not ported for: layers.7.attention_norm.eps\n",
      "Weights not ported for: layers.7.ffn_norm.eps\n",
      "Weights not ported for: layers.8.dim\n",
      "Weights not ported for: layers.8.n_heads\n",
      "Weights not ported for: layers.8.attention.dim\n",
      "Weights not ported for: layers.8.attention.n_heads\n",
      "Weights not ported for: layers.8.attention.head_dim\n",
      "Weights not ported for: layers.8.attention.n_kv_heads\n",
      "Weights not ported for: layers.8.attention.kv_repeats\n",
      "Weights not ported for: layers.8.attention.sliding_window\n",
      "Weights not ported for: layers.8.attention.scale\n",
      "Weights not ported for: layers.8.attention_norm.eps\n",
      "Weights not ported for: layers.8.ffn_norm.eps\n",
      "Weights not ported for: layers.9.dim\n",
      "Weights not ported for: layers.9.n_heads\n",
      "Weights not ported for: layers.9.attention.dim\n",
      "Weights not ported for: layers.9.attention.n_heads\n",
      "Weights not ported for: layers.9.attention.head_dim\n",
      "Weights not ported for: layers.9.attention.n_kv_heads\n",
      "Weights not ported for: layers.9.attention.kv_repeats\n",
      "Weights not ported for: layers.9.attention.sliding_window\n",
      "Weights not ported for: layers.9.attention.scale\n",
      "Weights not ported for: layers.9.attention_norm.eps\n",
      "Weights not ported for: layers.9.ffn_norm.eps\n",
      "Weights not ported for: layers.10.dim\n",
      "Weights not ported for: layers.10.n_heads\n",
      "Weights not ported for: layers.10.attention.dim\n",
      "Weights not ported for: layers.10.attention.n_heads\n",
      "Weights not ported for: layers.10.attention.head_dim\n",
      "Weights not ported for: layers.10.attention.n_kv_heads\n",
      "Weights not ported for: layers.10.attention.kv_repeats\n",
      "Weights not ported for: layers.10.attention.sliding_window\n",
      "Weights not ported for: layers.10.attention.scale\n",
      "Weights not ported for: layers.10.attention_norm.eps\n",
      "Weights not ported for: layers.10.ffn_norm.eps\n",
      "Weights not ported for: layers.11.dim\n",
      "Weights not ported for: layers.11.n_heads\n",
      "Weights not ported for: layers.11.attention.dim\n",
      "Weights not ported for: layers.11.attention.n_heads\n",
      "Weights not ported for: layers.11.attention.head_dim\n",
      "Weights not ported for: layers.11.attention.n_kv_heads\n",
      "Weights not ported for: layers.11.attention.kv_repeats\n",
      "Weights not ported for: layers.11.attention.sliding_window\n",
      "Weights not ported for: layers.11.attention.scale\n",
      "Weights not ported for: layers.11.attention_norm.eps\n",
      "Weights not ported for: layers.11.ffn_norm.eps\n",
      "Weights not ported for: layers.12.dim\n",
      "Weights not ported for: layers.12.n_heads\n",
      "Weights not ported for: layers.12.attention.dim\n",
      "Weights not ported for: layers.12.attention.n_heads\n",
      "Weights not ported for: layers.12.attention.head_dim\n",
      "Weights not ported for: layers.12.attention.n_kv_heads\n",
      "Weights not ported for: layers.12.attention.kv_repeats\n",
      "Weights not ported for: layers.12.attention.sliding_window\n",
      "Weights not ported for: layers.12.attention.scale\n",
      "Weights not ported for: layers.12.attention_norm.eps\n",
      "Weights not ported for: layers.12.ffn_norm.eps\n",
      "Weights not ported for: layers.13.dim\n",
      "Weights not ported for: layers.13.n_heads\n",
      "Weights not ported for: layers.13.attention.dim\n",
      "Weights not ported for: layers.13.attention.n_heads\n",
      "Weights not ported for: layers.13.attention.head_dim\n",
      "Weights not ported for: layers.13.attention.n_kv_heads\n",
      "Weights not ported for: layers.13.attention.kv_repeats\n",
      "Weights not ported for: layers.13.attention.sliding_window\n",
      "Weights not ported for: layers.13.attention.scale\n",
      "Weights not ported for: layers.13.attention_norm.eps\n",
      "Weights not ported for: layers.13.ffn_norm.eps\n",
      "Weights not ported for: layers.14.dim\n",
      "Weights not ported for: layers.14.n_heads\n",
      "Weights not ported for: layers.14.attention.dim\n",
      "Weights not ported for: layers.14.attention.n_heads\n",
      "Weights not ported for: layers.14.attention.head_dim\n",
      "Weights not ported for: layers.14.attention.n_kv_heads\n",
      "Weights not ported for: layers.14.attention.kv_repeats\n",
      "Weights not ported for: layers.14.attention.sliding_window\n",
      "Weights not ported for: layers.14.attention.scale\n",
      "Weights not ported for: layers.14.attention_norm.eps\n",
      "Weights not ported for: layers.14.ffn_norm.eps\n",
      "Weights not ported for: layers.15.dim\n",
      "Weights not ported for: layers.15.n_heads\n",
      "Weights not ported for: layers.15.attention.dim\n",
      "Weights not ported for: layers.15.attention.n_heads\n",
      "Weights not ported for: layers.15.attention.head_dim\n",
      "Weights not ported for: layers.15.attention.n_kv_heads\n",
      "Weights not ported for: layers.15.attention.kv_repeats\n",
      "Weights not ported for: layers.15.attention.sliding_window\n",
      "Weights not ported for: layers.15.attention.scale\n",
      "Weights not ported for: layers.15.attention_norm.eps\n",
      "Weights not ported for: layers.15.ffn_norm.eps\n",
      "Weights not ported for: layers.16.dim\n",
      "Weights not ported for: layers.16.n_heads\n",
      "Weights not ported for: layers.16.attention.dim\n",
      "Weights not ported for: layers.16.attention.n_heads\n",
      "Weights not ported for: layers.16.attention.head_dim\n",
      "Weights not ported for: layers.16.attention.n_kv_heads\n",
      "Weights not ported for: layers.16.attention.kv_repeats\n",
      "Weights not ported for: layers.16.attention.sliding_window\n",
      "Weights not ported for: layers.16.attention.scale\n",
      "Weights not ported for: layers.16.attention_norm.eps\n",
      "Weights not ported for: layers.16.ffn_norm.eps\n",
      "Weights not ported for: layers.17.dim\n",
      "Weights not ported for: layers.17.n_heads\n",
      "Weights not ported for: layers.17.attention.dim\n",
      "Weights not ported for: layers.17.attention.n_heads\n",
      "Weights not ported for: layers.17.attention.head_dim\n",
      "Weights not ported for: layers.17.attention.n_kv_heads\n",
      "Weights not ported for: layers.17.attention.kv_repeats\n",
      "Weights not ported for: layers.17.attention.sliding_window\n",
      "Weights not ported for: layers.17.attention.scale\n",
      "Weights not ported for: layers.17.attention_norm.eps\n",
      "Weights not ported for: layers.17.ffn_norm.eps\n",
      "Weights not ported for: layers.18.dim\n",
      "Weights not ported for: layers.18.n_heads\n",
      "Weights not ported for: layers.18.attention.dim\n",
      "Weights not ported for: layers.18.attention.n_heads\n",
      "Weights not ported for: layers.18.attention.head_dim\n",
      "Weights not ported for: layers.18.attention.n_kv_heads\n",
      "Weights not ported for: layers.18.attention.kv_repeats\n",
      "Weights not ported for: layers.18.attention.sliding_window\n",
      "Weights not ported for: layers.18.attention.scale\n",
      "Weights not ported for: layers.18.attention_norm.eps\n",
      "Weights not ported for: layers.18.ffn_norm.eps\n",
      "Weights not ported for: layers.19.dim\n",
      "Weights not ported for: layers.19.n_heads\n",
      "Weights not ported for: layers.19.attention.dim\n",
      "Weights not ported for: layers.19.attention.n_heads\n",
      "Weights not ported for: layers.19.attention.head_dim\n",
      "Weights not ported for: layers.19.attention.n_kv_heads\n",
      "Weights not ported for: layers.19.attention.kv_repeats\n",
      "Weights not ported for: layers.19.attention.sliding_window\n",
      "Weights not ported for: layers.19.attention.scale\n",
      "Weights not ported for: layers.19.attention_norm.eps\n",
      "Weights not ported for: layers.19.ffn_norm.eps\n",
      "Weights not ported for: layers.20.dim\n",
      "Weights not ported for: layers.20.n_heads\n",
      "Weights not ported for: layers.20.attention.dim\n",
      "Weights not ported for: layers.20.attention.n_heads\n",
      "Weights not ported for: layers.20.attention.head_dim\n",
      "Weights not ported for: layers.20.attention.n_kv_heads\n",
      "Weights not ported for: layers.20.attention.kv_repeats\n",
      "Weights not ported for: layers.20.attention.sliding_window\n",
      "Weights not ported for: layers.20.attention.scale\n",
      "Weights not ported for: layers.20.attention_norm.eps\n",
      "Weights not ported for: layers.20.ffn_norm.eps\n",
      "Weights not ported for: layers.21.dim\n",
      "Weights not ported for: layers.21.n_heads\n",
      "Weights not ported for: layers.21.attention.dim\n",
      "Weights not ported for: layers.21.attention.n_heads\n",
      "Weights not ported for: layers.21.attention.head_dim\n",
      "Weights not ported for: layers.21.attention.n_kv_heads\n",
      "Weights not ported for: layers.21.attention.kv_repeats\n",
      "Weights not ported for: layers.21.attention.sliding_window\n",
      "Weights not ported for: layers.21.attention.scale\n",
      "Weights not ported for: layers.21.attention_norm.eps\n",
      "Weights not ported for: layers.21.ffn_norm.eps\n",
      "Weights not ported for: layers.22.dim\n",
      "Weights not ported for: layers.22.n_heads\n",
      "Weights not ported for: layers.22.attention.dim\n",
      "Weights not ported for: layers.22.attention.n_heads\n",
      "Weights not ported for: layers.22.attention.head_dim\n",
      "Weights not ported for: layers.22.attention.n_kv_heads\n",
      "Weights not ported for: layers.22.attention.kv_repeats\n",
      "Weights not ported for: layers.22.attention.sliding_window\n",
      "Weights not ported for: layers.22.attention.scale\n",
      "Weights not ported for: layers.22.attention_norm.eps\n",
      "Weights not ported for: layers.22.ffn_norm.eps\n",
      "Weights not ported for: layers.23.dim\n",
      "Weights not ported for: layers.23.n_heads\n",
      "Weights not ported for: layers.23.attention.dim\n",
      "Weights not ported for: layers.23.attention.n_heads\n",
      "Weights not ported for: layers.23.attention.head_dim\n",
      "Weights not ported for: layers.23.attention.n_kv_heads\n",
      "Weights not ported for: layers.23.attention.kv_repeats\n",
      "Weights not ported for: layers.23.attention.sliding_window\n",
      "Weights not ported for: layers.23.attention.scale\n",
      "Weights not ported for: layers.23.attention_norm.eps\n",
      "Weights not ported for: layers.23.ffn_norm.eps\n",
      "Weights not ported for: layers.24.dim\n",
      "Weights not ported for: layers.24.n_heads\n",
      "Weights not ported for: layers.24.attention.dim\n",
      "Weights not ported for: layers.24.attention.n_heads\n",
      "Weights not ported for: layers.24.attention.head_dim\n",
      "Weights not ported for: layers.24.attention.n_kv_heads\n",
      "Weights not ported for: layers.24.attention.kv_repeats\n",
      "Weights not ported for: layers.24.attention.sliding_window\n",
      "Weights not ported for: layers.24.attention.scale\n",
      "Weights not ported for: layers.24.attention_norm.eps\n",
      "Weights not ported for: layers.24.ffn_norm.eps\n",
      "Weights not ported for: layers.25.dim\n",
      "Weights not ported for: layers.25.n_heads\n",
      "Weights not ported for: layers.25.attention.dim\n",
      "Weights not ported for: layers.25.attention.n_heads\n",
      "Weights not ported for: layers.25.attention.head_dim\n",
      "Weights not ported for: layers.25.attention.n_kv_heads\n",
      "Weights not ported for: layers.25.attention.kv_repeats\n",
      "Weights not ported for: layers.25.attention.sliding_window\n",
      "Weights not ported for: layers.25.attention.scale\n",
      "Weights not ported for: layers.25.attention_norm.eps\n",
      "Weights not ported for: layers.25.ffn_norm.eps\n",
      "Weights not ported for: layers.26.dim\n",
      "Weights not ported for: layers.26.n_heads\n",
      "Weights not ported for: layers.26.attention.dim\n",
      "Weights not ported for: layers.26.attention.n_heads\n",
      "Weights not ported for: layers.26.attention.head_dim\n",
      "Weights not ported for: layers.26.attention.n_kv_heads\n",
      "Weights not ported for: layers.26.attention.kv_repeats\n",
      "Weights not ported for: layers.26.attention.sliding_window\n",
      "Weights not ported for: layers.26.attention.scale\n",
      "Weights not ported for: layers.26.attention_norm.eps\n",
      "Weights not ported for: layers.26.ffn_norm.eps\n",
      "Weights not ported for: layers.27.dim\n",
      "Weights not ported for: layers.27.n_heads\n",
      "Weights not ported for: layers.27.attention.dim\n",
      "Weights not ported for: layers.27.attention.n_heads\n",
      "Weights not ported for: layers.27.attention.head_dim\n",
      "Weights not ported for: layers.27.attention.n_kv_heads\n",
      "Weights not ported for: layers.27.attention.kv_repeats\n",
      "Weights not ported for: layers.27.attention.sliding_window\n",
      "Weights not ported for: layers.27.attention.scale\n",
      "Weights not ported for: layers.27.attention_norm.eps\n",
      "Weights not ported for: layers.27.ffn_norm.eps\n",
      "Weights not ported for: layers.28.dim\n",
      "Weights not ported for: layers.28.n_heads\n",
      "Weights not ported for: layers.28.attention.dim\n",
      "Weights not ported for: layers.28.attention.n_heads\n",
      "Weights not ported for: layers.28.attention.head_dim\n",
      "Weights not ported for: layers.28.attention.n_kv_heads\n",
      "Weights not ported for: layers.28.attention.kv_repeats\n",
      "Weights not ported for: layers.28.attention.sliding_window\n",
      "Weights not ported for: layers.28.attention.scale\n",
      "Weights not ported for: layers.28.attention_norm.eps\n",
      "Weights not ported for: layers.28.ffn_norm.eps\n",
      "Weights not ported for: layers.29.dim\n",
      "Weights not ported for: layers.29.n_heads\n",
      "Weights not ported for: layers.29.attention.dim\n",
      "Weights not ported for: layers.29.attention.n_heads\n",
      "Weights not ported for: layers.29.attention.head_dim\n",
      "Weights not ported for: layers.29.attention.n_kv_heads\n",
      "Weights not ported for: layers.29.attention.kv_repeats\n",
      "Weights not ported for: layers.29.attention.sliding_window\n",
      "Weights not ported for: layers.29.attention.scale\n",
      "Weights not ported for: layers.29.attention_norm.eps\n",
      "Weights not ported for: layers.29.ffn_norm.eps\n",
      "Weights not ported for: layers.30.dim\n",
      "Weights not ported for: layers.30.n_heads\n",
      "Weights not ported for: layers.30.attention.dim\n",
      "Weights not ported for: layers.30.attention.n_heads\n",
      "Weights not ported for: layers.30.attention.head_dim\n",
      "Weights not ported for: layers.30.attention.n_kv_heads\n",
      "Weights not ported for: layers.30.attention.kv_repeats\n",
      "Weights not ported for: layers.30.attention.sliding_window\n",
      "Weights not ported for: layers.30.attention.scale\n",
      "Weights not ported for: layers.30.attention_norm.eps\n",
      "Weights not ported for: layers.30.ffn_norm.eps\n",
      "Weights not ported for: layers.31.dim\n",
      "Weights not ported for: layers.31.n_heads\n",
      "Weights not ported for: layers.31.attention.dim\n",
      "Weights not ported for: layers.31.attention.n_heads\n",
      "Weights not ported for: layers.31.attention.head_dim\n",
      "Weights not ported for: layers.31.attention.n_kv_heads\n",
      "Weights not ported for: layers.31.attention.kv_repeats\n",
      "Weights not ported for: layers.31.attention.sliding_window\n",
      "Weights not ported for: layers.31.attention.scale\n",
      "Weights not ported for: layers.31.attention_norm.eps\n",
      "Weights not ported for: layers.31.ffn_norm.eps\n",
      "Weights not ported for: norm.eps\n",
      "Weights not ported for: vocab_size\n",
      "Weights not ported for: n_layers\n",
      "Weights not ported for: sliding_window\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16) # sets architecutre\n",
    "model = port_weights_from_torch(state_dict, model) # fills with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7da969f6-eb91-4df5-9976-1db480914a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_k = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "# cache_v = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "NUM_ITERS = 15\n",
    "cos_freq, sin_freq = precompute_frequencies(args.head_dim, 128000)\n",
    "vmapped = jax.vmap(partial(model.parallel_call, num_iters=NUM_ITERS), in_axes=(0, None, None, None, None)) # vmapped is the name of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_seq = jax.vmap(\n",
    "    model,\n",
    "    in_axes=(0, None, None, None, None),\n",
    ")  # vmapped is the name of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d96e5-f58d-4ea4-b878-92abcfcb85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting deer outer loop\n",
      "\n",
      "-----------------\n",
      "iteration 0\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 1\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 2\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 3\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 4\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 5\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 6\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 7\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 8\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 9\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 10\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 11\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 12\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 13\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 14\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n"
     ]
    }
   ],
   "source": [
    "fake_pos = jnp.array([0], dtype=jnp.int32)\n",
    "fake_inp = jnp.asarray([[1]], dtype=jnp.int32)\n",
    "fake_mask = None\n",
    "\n",
    "hist_seq = vmap_seq(\n",
    "    fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask\n",
    ")\n",
    "hist_parr = vmapped(fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask)\n",
    "jnp.save(f\"seq_history.npy\", hist_seq)\n",
    "jnp.save(f\"parallel_history_NumIters_{NUM_ITERS}.npy\", hist_parr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 32, 1, 4096)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.load(\"parallel_history_NumIters_7.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 32, 1, 4096)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 1, 4096)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 32)\n"
     ]
    }
   ],
   "source": [
    "errors_per_iter_and_layer = jnp.mean(jnp.abs((hist_parr[0] - hist_seq).squeeze()), axis=-1)\n",
    "print(jnp.shape(errors_per_iter_and_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mean error in activations')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors_per_iter_and_layer[-2], label=\"iteration 6\")\n",
    "plt.plot(errors_per_iter_and_layer[-1], label=\"iteration 7\")\n",
    "plt.xlabel(\"layers\")\n",
    "plt.ylabel(\"mean error in activations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(errors_per_iter_and_layer, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhot\u001b[39m\u001b[38;5;124m\"\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(errors_per_iter_and_layer, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Partial(\n",
       "  func=_JitWrapper(\n",
       "    fn='Transformer.compute_norm',\n",
       "    filter_warning=False,\n",
       "    donate_first=False,\n",
       "    donate_rest=False\n",
       "  ),\n",
       "  args=(\n",
       "    Transformer(\n",
       "      tok_embeddings=Embedding(\n",
       "        num_embeddings=32000,\n",
       "        embedding_size=4096,\n",
       "        weight=bf16[32000,4096]\n",
       "      ),\n",
       "      layers=[\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        ),\n",
       "        TransformerBlock(\n",
       "          dim=4096,\n",
       "          n_heads=32,\n",
       "          attention=Attention(\n",
       "            dim=4096,\n",
       "            n_heads=32,\n",
       "            head_dim=128,\n",
       "            n_kv_heads=8,\n",
       "            kv_repeats=4,\n",
       "            sliding_window=4096,\n",
       "            scale=0.08838834764831845,\n",
       "            wq=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wk=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wv=Linear(\n",
       "              weight=bf16[1024,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=1024,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            wo=Linear(\n",
       "              weight=bf16[4096,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          attention_norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "          feed_forward=FeedForward(\n",
       "            w1=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w2=Linear(\n",
       "              weight=bf16[4096,14336],\n",
       "              bias=None,\n",
       "              in_features=14336,\n",
       "              out_features=4096,\n",
       "              use_bias=False\n",
       "            ),\n",
       "            w3=Linear(\n",
       "              weight=bf16[14336,4096],\n",
       "              bias=None,\n",
       "              in_features=4096,\n",
       "              out_features=14336,\n",
       "              use_bias=False\n",
       "            )\n",
       "          ),\n",
       "          ffn_norm=RMSNorm(eps=1e-05, weight=bf16[4096])\n",
       "        )\n",
       "      ],\n",
       "      norm=RMSNorm(eps=1e-05, weight=bf16[4096]),\n",
       "      output=Linear(\n",
       "        weight=bf16[32000,4096],\n",
       "        bias=None,\n",
       "        in_features=4096,\n",
       "        out_features=32000,\n",
       "        use_bias=False\n",
       "      ),\n",
       "      vocab_size=32000,\n",
       "      n_layers=32,\n",
       "      sliding_window=4096\n",
       "    ),\n",
       "  ),\n",
       "  keywords={}\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[[-8.92639160e-04,  2.65502930e-03, -1.84570312e-01, ...,\n",
       "            7.62939453e-06, -1.43432617e-03, -1.95312500e-03]],\n",
       "\n",
       "         [[-8.91094469e-03, -6.18494023e-03, -1.85622007e-01, ...,\n",
       "            9.09190509e-04, -5.82782552e-03, -1.42973997e-02]],\n",
       "\n",
       "         [[-6.07582554e-03, -3.72581817e-02, -1.96056485e-01, ...,\n",
       "           -2.17162538e-02, -3.14874249e-03, -9.00264457e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.10669410e+00,  1.49299145e-01, -5.95834732e-01, ...,\n",
       "            3.55023921e-01,  1.29173613e+00, -5.56365788e-01]],\n",
       "\n",
       "         [[ 1.05325460e+00,  1.63162947e-02, -5.39088607e-01, ...,\n",
       "            5.94611347e-01,  1.15215635e+00, -6.52567387e-01]],\n",
       "\n",
       "         [[ 4.23761547e-01,  2.28124112e-01, -1.06671560e+00, ...,\n",
       "            5.91840267e-01,  8.96652579e-01, -7.07928896e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.92639160e-04,  2.65502930e-03, -1.84570312e-01, ...,\n",
       "            7.62939453e-06, -1.43432617e-03, -1.95312500e-03]],\n",
       "\n",
       "         [[-1.20094955e-01, -3.91652256e-01, -1.39715612e-01, ...,\n",
       "            7.06485100e-03,  2.07763314e-02, -5.91178797e-02]],\n",
       "\n",
       "         [[-1.16284236e-01, -4.00582671e-01, -2.51705170e-01, ...,\n",
       "            2.94541754e-02,  1.13582872e-02, -9.83709916e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.72007227e+00,  1.60713234e+01, -9.77484894e+00, ...,\n",
       "           -4.83511925e+00,  2.95893650e+01, -2.57335949e+00]],\n",
       "\n",
       "         [[ 9.25865936e+00,  1.67624340e+01, -5.88470030e+00, ...,\n",
       "            4.59273815e-01,  3.09054546e+01, -3.87069154e+00]],\n",
       "\n",
       "         [[ 1.20738783e+01,  1.76835766e+01, -8.13421631e+00, ...,\n",
       "            2.23497677e+00,  3.07850189e+01, -5.26595545e+00]]]]],      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "75b07b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp_flat = jnp.asarray([1, 832, 349, 265, 1369], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "07a00741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.000892639, 0.00265503, -0.18457, ..., 7.62939e-06,\n",
       "         -0.00143433, -0.00195312],\n",
       "        [0.00537109, 0.0018158, 0.00552368, ..., 0.00354004,\n",
       "         -0.000892639, 0.000926971],\n",
       "        [0.00579834, 0.00128937, 0.00546265, ..., 0.00196838,\n",
       "         -0.00120544, -0.00204468],\n",
       "        [0.00314331, 0.000362396, 0.00439453, ..., 0.000984192,\n",
       "         0.00153351, 0.00172424],\n",
       "        [0.00219727, 0.00561523, 0.00280762, ..., 0.00230408,\n",
       "         0.00222778, -0.000953674]],\n",
       "\n",
       "       [[-0.120117, -0.392578, -0.139648, ..., 0.00674438, 0.020752,\n",
       "         -0.059082],\n",
       "        [0.00115967, -0.00131226, 0.00242615, ..., 0.0114136,\n",
       "         -0.00276184, -0.000175476],\n",
       "        [0.00506592, 0.00265503, 0.00567627, ..., 0.00622559,\n",
       "         -0.0065918, -0.0043335],\n",
       "        [0.000976562, -0.00344849, 0.0111694, ..., 0.00891113,\n",
       "         -0.00165558, -9.15527e-05],\n",
       "        [0.00546265, 0.00460815, 0.00469971, ..., -0.000923157,\n",
       "         -0.000442505, -0.0078125]],\n",
       "\n",
       "       [[-0.121582, -0.392578, -0.140625, ..., 0.00622559, 0.0209961,\n",
       "         -0.0600586],\n",
       "        [-0.000591278, -0.00970459, 0.00531006, ..., 0.0177002,\n",
       "         0.00062561, -0.00817871],\n",
       "        [0.0065918, 7.62939e-05, 0.00305176, ..., 0.0136719, -0.0135498,\n",
       "         -0.00128174],\n",
       "        [-0.000236511, -3.05176e-05, 0.0106812, ..., 0.019043,\n",
       "         -0.00854492, -0.00171661],\n",
       "        [0.00192261, -0.0020752, 0.00750732, ..., 0.00386047,\n",
       "         -0.00454712, -0.00817871]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.527344, -0.570312, -0.314453, ..., -0.578125, -0.40625,\n",
       "         -0.090332],\n",
       "        [-1.04688, 0.00927734, 0.00500488, ..., 0.503906, -0.449219,\n",
       "         -0.0654297],\n",
       "        [0.015625, -0.0483398, 0.167969, ..., 0.34375, -0.15332,\n",
       "         0.416016],\n",
       "        [-0.186523, 0.0078125, 0.146484, ..., 0.0761719, -0.71875,\n",
       "         0.435547],\n",
       "        [-0.0263672, -0.0253906, 0.0388184, ..., -0.292969, -0.503906,\n",
       "         -0.0305176]],\n",
       "\n",
       "       [[-0.914062, -0.90625, -1.01562, ..., -1.11719, -0.617188,\n",
       "         0.151367],\n",
       "        [-1.07812, -0.308594, 0.0322266, ..., 0.644531, -0.458984,\n",
       "         -0.105957],\n",
       "        [0.166992, -0.0170898, 0.0146484, ..., 0.535156, -0.229492,\n",
       "         0.609375],\n",
       "        [-0.165039, -0.174805, 0.175781, ..., -0.192383, -0.707031,\n",
       "         0.388672],\n",
       "        [0.113281, 0.0927734, 0.166016, ..., -0.257812, -0.621094,\n",
       "         -0.105957]],\n",
       "\n",
       "       [[-1.60938, 0.472656, -1.625, ..., -0.0390625, -1.82031, 2.5625],\n",
       "        [-1.36719, 0.243164, -0.225586, ..., 0.75, -0.617188, -0.34375],\n",
       "        [0.0698242, 0.466797, -0.0432129, ..., 0.53125, -0.208984,\n",
       "         0.488281],\n",
       "        [0.207031, -0.0561523, 0.180664, ..., -0.11377, -0.408203,\n",
       "         0.455078],\n",
       "        [0.232422, 0.212891, 0.050293, ..., -0.34375, -0.695312,\n",
       "         -0.182617]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(fake_inp_flat, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.RMSNorm"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.0936636, dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sqrt(jnp.mean(logits[0, -1, 0] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a3b4f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(5.442458, dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sqrt(jnp.mean(model.norm(logits[0, -1, 0]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7b45669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp_flat = jnp.asarray([1, 832, 349, 265, 1369], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d2ae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4ffc5c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000, 64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89ac0483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_embeddings(fake_inp_flat).shape # (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc248cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.compute_embeddings(fake_inp_flat)\n",
    "xq, xk, xv = attn.compute_qkv(x)\n",
    "key, value = attn.prefill(xk, xv)\n",
    "output = attn.compute_scores_and_output(xq, key, value, fake_mask, x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406da556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e23a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a4e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a71fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape # (T, n_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4f380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk.shape # (T, n_kv_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.shape # (T, n_kv_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.compute_scores_and_output(xq, xk, xv, fake_mask, 5).shape # (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5374a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_inp_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 96\u001b[0m, in \u001b[0;36mAttention.__call__\u001b[0;34m(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\u001b[0m\n\u001b[1;32m     93\u001b[0m xk \u001b[38;5;241m=\u001b[39m calculate_rope(xk, cos_freq, sin_freq, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# 3. Update cache\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m cache_k, cache_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_cache_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 4. Generation\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m positions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# prefill\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mAttention.update_cache_values\u001b[0;34m(self, xk, xv, cache_k, cache_v, positions)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_cache_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, xk, xv, cache_k, cache_v, positions):\n\u001b[0;32m---> 53\u001b[0m     cache_k \u001b[38;5;241m=\u001b[39m \u001b[43mcache_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mset(xk[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     54\u001b[0m     cache_v \u001b[38;5;241m=\u001b[39m cache_v\u001b[38;5;241m.\u001b[39mat[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mset(xv[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache_k, cache_v\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'at'"
     ]
    }
   ],
   "source": [
    "attn(model.compute_embeddings(fake_inp_flat), cos_freq[:5], sin_freq[:5], fake_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3410598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc44e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(model.compute_embeddings)(fake_inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 32000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # (batch, T, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a48e48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_inp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcos_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msin_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# x is of shape (seqlen, )\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     56\u001b[0m         seqlen \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/_module.py:1189\u001b[0m, in \u001b[0;36mPartial.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the wrapped `self.func`.\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m \n\u001b[1;32m   1179\u001b[0m \u001b[38;5;124;03m    **Arguments:**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03m    The result of the wrapped function.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mTransformer.compute_embeddings\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/nn/_embedding.py:101\u001b[0m, in \u001b[0;36mEmbedding.__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[x]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `jax.vmap` if you would like to index with multiple values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values."
     ]
    }
   ],
   "source": [
    "model(\n",
    "    fake_inp,\n",
    "    cos_freq[fake_pos],\n",
    "    sin_freq[fake_pos],\n",
    "    fake_pos,\n",
    "    fake_mask,\n",
    "    cache_k,\n",
    "    cache_v,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/nn/_embedding.py\u001b[0m(101)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m            raise ValueError(\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m                \u001b[0;34m\"`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    103 \u001b[0;31m                \u001b[0;34m\"Use `jax.vmap` if you would like to index with multiple values.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/contextlib.py\u001b[0m(81)\u001b[0;36minner\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     79 \u001b[0;31m        \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     80 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 81 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     82 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py\u001b[0m(24)\u001b[0;36mcompute_embeddings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     22 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 24 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31m    [... skipped 3 hidden frame(s)]\u001b[0m\n",
      "\n",
      "(1, 5)\n",
      "*** ValueError: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.\n",
      "*** ValueError: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.\n",
      "*** jax.errors.UnexpectedTracerError: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type int32[1,5] wrapped in a DynamicJaxprTracer to escape the scope of the transformation.\n",
      "JAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\n",
      "The function being traced when the value leaked was compute_embeddings at /Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/_jit.py:37 traced for jit.\n",
      "------------------------------\n",
      "The leaked intermediate value was created on line /var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py:53:12 (Transformer.__call__). \n",
      "------------------------------\n",
      "When the value was created, the final 5 stack frames (most recent last) excluding JAX-internal frames were:\n",
      "------------------------------\n",
      "<frozen runpy>:198:11 (_run_module_as_main)\n",
      "<frozen runpy>:88:4 (_run_code)\n",
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/1221483641.py:1 (<module>)\n",
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py:53:12 (Transformer.__call__)\n",
      "------------------------------\n",
      "\n",
      "To catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223d912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-eqx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
