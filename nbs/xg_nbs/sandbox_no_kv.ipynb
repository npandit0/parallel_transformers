{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20359b8e",
   "metadata": {},
   "source": [
    "# Model generation without the kv cache\n",
    "\n",
    "Let's see if we can get the code to work with turning the kv cache off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313c140-421d-4f1f-a283-3461b8db70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "from functools import partial\n",
    "from equinox._misc import default_floating_dtype\n",
    "from jaxtyping import Array, Float, Scalar\n",
    "from typing import Optional, Tuple, List, NamedTuple\n",
    "\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "import pdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9a7657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672df14d-d052-403a-8b68-b94a6240abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CPU for torch\n",
    "device  = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7533de2e-9d14-411a-a55a-852cb62646c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_35568/445611555.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "# Load the model dict, and check if any GPU is used\n",
    "# state_dict = torch.load(\"mistral-7B-v0.1/consolidated.00.pth\")\n",
    "state_dict = torch.load(\n",
    "    \"/Users/xaviergonzalez/Desktop/xavier_folders/stanford/cs229s/mistral_jax/model_files/consolidated.00.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27c428-fd21-41a1-9a5c-99a966f5a2a3",
   "metadata": {},
   "source": [
    "# 1. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd26d27d-8e7e-46e9-ba8d-187a8a57a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self._model = SentencePieceProcessor(model_file=model_path)\n",
    "\n",
    "    @property\n",
    "    def eos_id(self) -> int:\n",
    "        return self._model.eos_id()\n",
    "\n",
    "    @property\n",
    "    def pad_id(self) -> int:\n",
    "        return self._model.pad_id()\n",
    "\n",
    "    def encode(self, s: str) -> List[int]:\n",
    "        return [self._model.bos_id(), *self._model.encode(s)]\n",
    "\n",
    "    def decode(self, t: List[int]) -> str:\n",
    "        return self._model.decode(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5aced-2da9-42df-900d-b9d11d5f45fa",
   "metadata": {},
   "source": [
    "# 2. RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "431e5fa1-25dd-401a-abfb-1371f5f1b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_frequencies(dim, max_pos, theta=10000.0):\n",
    "    inv_freq = 1.0 / (\n",
    "        theta ** (jnp.arange(0, dim, 2, dtype=jnp.float32)[: (dim // 2)] / dim)\n",
    "    )\n",
    "    t = jnp.arange(0, max_pos, dtype=jnp.float32)\n",
    "    freqs = jnp.outer(t, inv_freq)\n",
    "    return jnp.cos(freqs), jnp.sin(freqs)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3,))\n",
    "def calculate_rope(x, cos_freq, sin_freq, offset=0):\n",
    "    # x shape  is [seqlen, num_heads, heads_dim]\n",
    "\n",
    "    # Get the sequence length\n",
    "    seqlen = x.shape[0]\n",
    "\n",
    "    # Get the corresponding positional embeddings\n",
    "    sin = sin_freq[offset : offset + seqlen, :]\n",
    "    cos = cos_freq[offset : offset + seqlen, :]\n",
    "\n",
    "    # Positional embeddings are 2D while our input is 3D\n",
    "    # if `num_heads` dimension is present in the inputs.\n",
    "    # We need to add another dimension to our positional embeddings\n",
    "    sin = sin[:, jnp.newaxis, :]\n",
    "    cos = cos[:, jnp.newaxis, :]\n",
    "\n",
    "    # Get the even-odd positions from the inputs\n",
    "    x1 = x[..., 0::2]\n",
    "    x2 = x[..., 1::2]\n",
    "\n",
    "    # Matmul with the rotation matrix\n",
    "    # [cos_nθ, -sin_nθ] [x1]\n",
    "    # [sin_nθ,  cos_nθ] [x2]\n",
    "    # => [x1 * cos_nθ - x2 * sin_nθ, x1 * sin_nθ + x2 * cos_nθ]\n",
    "    pos_embed = jnp.stack([x1 * cos - x2 * sin, x1 * sin + x2 * cos], axis=-1)\n",
    "    pos_embed = jax.lax.collapse(pos_embed, -2)\n",
    "    return pos_embed.astype(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1aa31-614e-4483-8599-c5f0b4623292",
   "metadata": {},
   "source": [
    "# 3. RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180fbb2d-ce6f-4b1a-a198-e4f37fab93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(eqx.Module):\n",
    "    eps: float\n",
    "    weight: Float[Array, \"*shape\"]\n",
    "\n",
    "    def __init__(self, dim, eps, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        self.eps = eps\n",
    "        self.weight = jnp.ones(shape=dim, dtype=dtype)\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * jax.lax.rsqrt(jnp.mean(x **2 , keepdims=True) + self.eps)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = self._norm(x.astype(jnp.float32)).astype(x.dtype)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f9a21-bb3c-45e8-805c-5f8605f72423",
   "metadata": {},
   "source": [
    "# 4. FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efffa74f-556b-4c3e-9f73-e23acfa1da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(eqx.Module):\n",
    "    w1: eqx.nn.Linear\n",
    "    w2: eqx.nn.Linear\n",
    "    w3: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "        self.w1 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.w2 = eqx.nn.Linear(args.hidden_dim, args.dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.w3 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = jax.nn.silu(self.w1(x).astype(jnp.float32)).astype(x.dtype)\n",
    "        return self.w2(h * self.w3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c459d5-b30d-48e5-924b-ea661542e8a2",
   "metadata": {},
   "source": [
    "# 5. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2048b724-3015-43c8-be5e-0214eb83af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    head_dim: int\n",
    "    n_kv_heads: int\n",
    "    kv_repeats: int\n",
    "    sliding_window: int\n",
    "    scale: float\n",
    "    wq: eqx.nn.Linear\n",
    "    wk: eqx.nn.Linear\n",
    "    wv: eqx.nn.Linear\n",
    "    wo: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.head_dim\n",
    "        self.n_kv_heads = args.n_kv_heads\n",
    "        self.dim = args.dim\n",
    "        self.kv_repeats = self.n_heads // self.n_kv_heads\n",
    "        self.sliding_window = args.sliding_window\n",
    "\n",
    "        self.scale = args.head_dim**-0.5\n",
    "\n",
    "        self.wq = eqx.nn.Linear(args.dim, args.n_heads * args.head_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.wk = eqx.nn.Linear(args.dim, args.n_kv_heads * args.head_dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.wv = eqx.nn.Linear(args.dim, args.n_kv_heads * args.head_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "        self.wo = eqx.nn.Linear(args.n_heads * args.head_dim, args.dim, use_bias=False, key=key4, dtype=dtype)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(2, 3))\n",
    "    def get_cache_slice(self, x, pos, kv_repeats):\n",
    "        x_slice = x.at[:pos, :, :].get()\n",
    "        x_slice = jnp.repeat(x_slice, kv_repeats, axis=1)\n",
    "        return x_slice\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_qkv(self, x):\n",
    "        seqlen, _ = x.shape\n",
    "\n",
    "        xq = jax.vmap(self.wq)(x)\n",
    "        xk = jax.vmap(self.wk)(x)\n",
    "        xv = jax.vmap(self.wv)(x)\n",
    "\n",
    "        xq = jnp.reshape(xq, (seqlen, self.n_heads, self.head_dim))\n",
    "        xk = jnp.reshape(xk, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        xv = jnp.reshape(xv, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        return xq, xk, xv\n",
    "\n",
    "    @jax.jit\n",
    "    def update_cache_values(self, xk, xv, cache_k, cache_v, positions):\n",
    "        cache_k = cache_k.at[positions, ...].set(xk[positions, ...])\n",
    "        cache_v = cache_v.at[positions, ...].set(xv[positions, ...])\n",
    "        return cache_k, cache_v\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def prefill(self, xk, xv):\n",
    "        key = jnp.repeat(xk, self.kv_repeats, axis=1)\n",
    "        value = jnp.repeat(xv, self.kv_repeats, axis=1)\n",
    "        return key, value\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_scores_and_output(self, xq, key, value, mask, seqlen):\n",
    "        query = jnp.transpose(xq, (1, 0, 2))\n",
    "        key = jnp.transpose(key, (1, 0, 2))\n",
    "        value = jnp.transpose(value, (1, 0, 2))\n",
    "\n",
    "        # # # scores : [n_heads, seqlen | 1, seqlen]\n",
    "        scores = jnp.matmul(query, jnp.transpose(key, (0, 2, 1))) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            # Mask will of shape [seqlen, seqlen] but our scores\n",
    "            # have shape [num_heads, seqlen, seqlen], hence we need\n",
    "            # to introduce another dimension in the mask\n",
    "            mask = mask[jnp.newaxis, ...]\n",
    "            scores = scores + mask\n",
    "\n",
    "        scores = jax.nn.softmax(scores.astype(jnp.float32), axis=-1).astype(query.dtype)\n",
    "        output = jnp.matmul(scores, value)\n",
    "        output = jnp.reshape(jnp.transpose(output, (1, 0, 2)), (seqlen, -1))\n",
    "        output = jax.vmap(self.wo)(output)\n",
    "        return output\n",
    "\n",
    "    def __call__(self,  x, cos_freq, sin_freq, positions, mask=None, cache_k=None, cache_v=None):\n",
    "        # x shape: [seqlen, embed_dim]\n",
    "        seqlen, _ = x.shape\n",
    "        # 1. Calculate qkv\n",
    "        xq, xk, xv = self.compute_qkv(x)\n",
    "\n",
    "        # 2. Calculate RoPE\n",
    "        xq = calculate_rope(xq, cos_freq, sin_freq, 0)\n",
    "        xk = calculate_rope(xk, cos_freq, sin_freq, 0)\n",
    "\n",
    "        key, value = self.prefill(xk, xv)\n",
    "\n",
    "        # # 3. Update cache\n",
    "        # cache_k, cache_v = self.update_cache_values(xk, xv, cache_k, cache_v, positions)\n",
    "\n",
    "        # # 4. Generation\n",
    "        # if positions.shape[0] > 1:\n",
    "        #     # prefill\n",
    "        #     key, value = self.prefill(xk, xv)\n",
    "        # else:\n",
    "        #     # single-token generation\n",
    "        #     cur_pos = positions[-1].item() + 1\n",
    "        #     key = self.get_cache_slice(cache_k, cur_pos, self.kv_repeats)\n",
    "        #     value = self.get_cache_slice(cache_v, cur_pos, self.kv_repeats)\n",
    "\n",
    "        # 5. Output\n",
    "        output = self.compute_scores_and_output(xq, key, value, mask, seqlen)\n",
    "        # return output, cache_k, cache_v\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a123d-c4b1-44f0-a6cd-5daf67c63adb",
   "metadata": {},
   "source": [
    "# 6. TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84cb56f-1a8f-4c28-9f3e-2c180f5e86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    attention: Attention\n",
    "    attention_norm: RMSNorm\n",
    "    feed_forward: FeedForward\n",
    "    ffn_norm: RMSNorm\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "\n",
    "        self.attention = Attention(args, key=key1, dtype=dtype)\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "        self.feed_forward = FeedForward(args, key=key2, dtype=dtype)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "    # def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask):\n",
    "        normed_x = jax.vmap(self.attention_norm)(x)\n",
    "        # r, cache_k, cache_v = self.attention(normed_x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\n",
    "        r = self.attention(\n",
    "            normed_x, cos_freq, sin_freq, positions, mask\n",
    "        )\n",
    "        h = x + r\n",
    "        r = jax.vmap(self.feed_forward)(jax.vmap(self.ffn_norm)(h))\n",
    "        out = h + r\n",
    "        return out\n",
    "        # return out, cache_k, cache_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f9502-010b-42ca-86ac-666e9476ff5c",
   "metadata": {},
   "source": [
    "# 7. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec9a64-57c4-4fb5-8e8a-c3ecb4e5bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(eqx.Module):\n",
    "    tok_embeddings: eqx.nn.Embedding\n",
    "    layers: TransformerBlock\n",
    "    norm: RMSNorm\n",
    "    output: eqx.nn.Linear\n",
    "    vocab_size: int\n",
    "    n_layers: int\n",
    "    sliding_window: int\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        self.sliding_window = args.sliding_window\n",
    "        keys = jax.random.split(key, args.n_layers + 2)\n",
    "        embed_key, linear_key, tf_layers_keys = keys[0], keys[1], keys[2:]\n",
    "\n",
    "        self.tok_embeddings = eqx.nn.Embedding(args.vocab_size, args.dim, key=embed_key, dtype=dtype)\n",
    "        self.norm = RMSNorm(dim=args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "        self.output = eqx.nn.Linear(args.dim, args.vocab_size, use_bias=False, key=linear_key, dtype=dtype)\n",
    "        self.layers = [TransformerBlock(args, key=tf_layers_keys[i], dtype=dtype) for i in range(args.n_layers)] \n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_embeddings(self, x):\n",
    "        return jax.vmap(self.tok_embeddings)(x)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_mask(self, seqlen):\n",
    "        t = jnp.full((seqlen, seqlen), dtype=jnp.bfloat16, fill_value=1)\n",
    "        mask = jnp.tril(t, k=0)\n",
    "        # make the mask banded to account for sliding window\n",
    "        mask = jnp.triu(mask, k=-self.sliding_window)\n",
    "        mask = jnp.log(mask)\n",
    "        return mask\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_norm(self, x):\n",
    "        return jax.vmap(self.norm)(x)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_output(self, x):\n",
    "        return jax.vmap(self.output)(x)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(1,))\n",
    "    def update_cache_values(self, idx, cache_k, cache_v, cache_k_updates, cache_v_updates):\n",
    "        cache_k = cache_k.at[idx, :, :, :].set(cache_k_updates)\n",
    "        cache_v = cache_v.at[idx, :, :, :].set(cache_v_updates)\n",
    "        return cache_k, cache_v\n",
    "\n",
    "    # def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "    #     # x is of shape (seqlen, )\n",
    "    #     h = self.compute_embeddings(x)\n",
    "\n",
    "    #     if x.shape[-1] > 1:\n",
    "    #         seqlen = x.shape[-1]\n",
    "    #         mask = self.compute_mask(seqlen)\n",
    "    #     else:\n",
    "    #         mask = None\n",
    "\n",
    "    #     # the for loop!!!\n",
    "\n",
    "    #     for i, layer in enumerate(self.layers):\n",
    "    #         #pdb.set_trace()\n",
    "    #         # h has shape (len(positions), dim)\n",
    "    #         # cache_ki has shape (sliding_window_len, head_dim, n_kv_heads)\n",
    "    #         h, cache_ki, cache_vi = layer(h, cos_freq, sin_freq, positions, mask, cache_k[i, ...], cache_v[i, ...]) # I think we could get away with creating blank entries for h, cache_ki, and cache_vi\n",
    "    #         # pdb.set_trace()\n",
    "    #         cache_k, cache_v = self.update_cache_values(i, cache_k, cache_v, cache_ki, cache_vi) # I think all this line is doing is plugging in cache_ki and cache_vi in the appropriate palce\n",
    "\n",
    "    #     h = self.compute_norm(h)\n",
    "    #     h = self.compute_output(h).astype(jnp.float32)\n",
    "    #     return h, cache_k, cache_v\n",
    "\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask):\n",
    "        \"\"\"\n",
    "        Edited to do prefilling instead of kv cache\n",
    "        \"\"\"\n",
    "        # x is of shape (seqlen, )\n",
    "        h = self.compute_embeddings(x)\n",
    "\n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # h has shape (len(positions), dim)\n",
    "            # cache_ki has shape (sliding_window_len, head_dim, n_kv_heads)\n",
    "            h = layer(h, cos_freq, sin_freq, positions, mask) # h has shape (T,D)\n",
    "            # print(f\"at layer {i}, the shape of the feature is {h.shape}\")\n",
    "\n",
    "        h = self.compute_norm(h)\n",
    "        h = self.compute_output(h).astype(jnp.float32)\n",
    "        return h\n",
    "    \n",
    "    def partial_layers(self, layers, cos_freq, sin_freq, positions, mask):\n",
    "        \"\"\"\n",
    "        Ideally we could use jtu instead...\n",
    "        \"\"\"\n",
    "        def partial_layer(layer):\n",
    "            return partial(layer.__call__, cos_freq=cos_freq, sin_freq=sin_freq, positions=positions, mask=mask)\n",
    "        \n",
    "        return [partial_layer(layer) for layer in layers] # really would prefer not to use list comprehension\n",
    "\n",
    "    def parallel_call(self, x, cos_freq, sin_freq, positions, mask, num_iters=7):\n",
    "        \"\"\"\n",
    "        Should give the same output as call, but using fixed point iterations\n",
    "        \"\"\"\n",
    "        h0 = self.compute_embeddings(x)\n",
    "        T, D = h0.shape\n",
    "\n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        # parallel logic\n",
    "        num_layers = len(self.layers)\n",
    "        # pdb.set_trace()\n",
    "        partialed_layers = self.partial_layers(self.layers, cos_freq, sin_freq, positions, mask)\n",
    "        states_guess = [jnp.zeros((T, D)) for _ in range(num_layers)] # we can probably play around with smarter initialization strategies, too\n",
    "        all_states = deer(h0, partialed_layers, states_guess, num_iters) # (num_iters, num_layers, T, D)\n",
    "        h = all_states[-1, -1]\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        h = self.compute_norm(h)\n",
    "        h = self.compute_output(h).astype(jnp.float32)\n",
    "        return h\n",
    "\n",
    "\n",
    "def deer(x, layers, states_guess, num_iters):\n",
    "    \"\"\"\n",
    "    runs deer (fiddly logic in the rearrange)\n",
    "\n",
    "    Args:\n",
    "      x: (T, d) initial inputs to transformer stack\n",
    "      layers: list of TransformerLayer objects (the functions that propagate information over the stack)\n",
    "      states_guess: list of length num_layers of (T, D) shaped arrays\n",
    "      num_iters: number of iterations to run for\n",
    "    \"\"\"\n",
    "    T, D = x.shape\n",
    "    num_layers = len(layers)\n",
    "\n",
    "    @jax.vmap\n",
    "    def binary_op(q_i, q_j):\n",
    "        \"\"\"Binary operator for parallel scan of linear recurrence. Assumes a full Jacobian matrix A\n",
    "        Args:\n",
    "            q_i: tuple containing J_i and b_i at position i       (P,P), (P,)\n",
    "            q_j: tuple containing J_j and b_j at position j       (P,P), (P,)\n",
    "        Returns:\n",
    "            new element ( A_out, Bu_out )\n",
    "        \"\"\"\n",
    "        A_i, b_i = q_i\n",
    "        A_j, b_j = q_j\n",
    "        return A_j @ A_i, A_j @ b_i + b_j\n",
    "\n",
    "    def step(states, args):\n",
    "        \"\"\"\n",
    "        This step is a single deer iteration (will eventually be sequential scanned)\n",
    "        Args:\n",
    "          states: list of length num_layers of (T, D) shaped arrays\n",
    "          args: None\n",
    "        \"\"\"\n",
    "        states = [x] + states[:-1]  # length num_layers\n",
    "        fs = jnp.array(\n",
    "            jtu.tree_map(lambda x, f: f(x), states, layers)\n",
    "        )  # (num_layers, T,D) arrays, note that we keep states as a list so we can use jtu.tree_map\n",
    "        As = jnp.array(\n",
    "            jtu.tree_map(lambda x, f: jax.jacrev(f)(x), states, layers)\n",
    "        )  # (num_layers, T, D, T, D) tensors\n",
    "        As = As.at[0].set(jnp.zeros((T, D, T, D)))\n",
    "        # pdb.set_trace()\n",
    "        # need to make the first A equal to zero\n",
    "        states = jnp.array(states)  # (num_layers, T,D)\n",
    "        # do some rearranging\n",
    "        flattened_states = jnp.reshape(states, (num_layers, T * D))  # (num_layers, T*D)\n",
    "        flattened_As = jnp.reshape(\n",
    "            As, (num_layers, T * D, T * D)\n",
    "        )  # (num_layers, T*D, T*D)\n",
    "        print(f\"{jnp.eigvals(flattened_As[0])}\")\n",
    "        # pdb.set_trace()\n",
    "        flattened_fs = jnp.reshape(fs, (num_layers, T * D))  # (num_layers, T*D)\n",
    "        bs = flattened_fs - jnp.einsum(\n",
    "            \"tij,tj->ti\", flattened_As, flattened_states\n",
    "        )  # (num_layers, T*D)\n",
    "\n",
    "        # finally ready to evaluate linearized dynamics (in parallel)\n",
    "        _, new_states = jax.lax.associative_scan(\n",
    "            binary_op, (flattened_As, bs)\n",
    "        )  # parallel operation\n",
    "        # new_states = jnp.nan_to_num(new_states)  # zero out nans, (num_layers, T*D)\n",
    "        new_states = jnp.reshape(new_states, (num_layers, T, D))  # (num_layers, T, D)\n",
    "        return list(new_states), new_states\n",
    "\n",
    "    print(\"starting deer outer loop\")\n",
    "    # _, iter_hist = jax.lax.scan(\n",
    "    #     step, states_guess, None, length=num_iters\n",
    "    # )  # state_iters will show all the intermediate traces\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        print()\n",
    "        print(\"-----------------\")\n",
    "        print(f\"iteration {i}\")\n",
    "        print(\"-----------------\")\n",
    "        print()\n",
    "        states_guess, _ = step(states_guess, None)\n",
    "\n",
    "    return states_guess\n",
    "    # return iter_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5a7c63f-4be6-4bad-b6f5-b77c77bcc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArgs(NamedTuple):\n",
    "    dim: int\n",
    "    n_layers: int\n",
    "    n_heads: int\n",
    "    n_kv_heads: int\n",
    "    head_dim: int\n",
    "    hidden_dim: int\n",
    "    vocab_size: int\n",
    "    sliding_window: int\n",
    "    norm_eps: float\n",
    "    max_batch_size: int = 1\n",
    "\n",
    "# maybe we could do a proto_params.json, and just not load in the weights\n",
    "with open(\n",
    "    \"/Users/xaviergonzalez/Desktop/xavier_folders/stanford/cs229s/mistral_jax/model_files/proto_params.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    # with open('./mistral-7B-v0.1/params.json', 'r') as f:\n",
    "    args = ModelArgs(**json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16a2d2cf-40f6-48af-a70f-37847532e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_weights_from_torch(torch_weights, eqx_model):\n",
    "    def load_weights(path, leaf):\n",
    "        path_pieces = []\n",
    "        for path_elem in path:\n",
    "            if isinstance(path_elem, jax.tree_util.GetAttrKey):\n",
    "                 path_pieces.append(path_elem.name)\n",
    "            elif isinstance(path_elem, jax.tree_util.SequenceKey):\n",
    "                 path_pieces.append(str(path_elem.idx))\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported path type {type(path_elem)}\")\n",
    "\n",
    "        path_pieces = \".\".join(path_pieces)\n",
    "        \n",
    "        if \"weight\" in path_pieces:\n",
    "            weight = torch_weights[path_pieces]\n",
    "            weight = jnp.asarray(weight.float().numpy(), dtype=jnp.bfloat16)\n",
    "            assert weight.shape == leaf.shape\n",
    "            assert weight.dtype == leaf.dtype\n",
    "            return weight\n",
    "        else:\n",
    "            print(f\"Weights not ported for: {path_pieces}\")\n",
    "            return leaf\n",
    "\n",
    "    return jax.tree_util.tree_map_with_path(load_weights, eqx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67530c78-98a9-4f84-aa4b-af0819b5f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16) # sets architecutre\n",
    "# model = port_weights_from_torch(state_dict, model) # fills with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7da969f6-eb91-4df5-9976-1db480914a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_k = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "# cache_v = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "cos_freq, sin_freq = precompute_frequencies(args.head_dim, 128000)\n",
    "vmapped = jax.vmap(partial(model.parallel_call, num_iters=15), in_axes=(0, None, None, None, None)) # vmapped is the name of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "001d96e5-f58d-4ea4-b878-92abcfcb85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting deer outer loop\n",
      "iteration 0\n",
      "> \u001b[0;32m/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_35568/3980512497.py\u001b[0m(182)\u001b[0;36mstep\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    180 \u001b[0;31m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    181 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 182 \u001b[0;31m        \u001b[0mflattened_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    183 \u001b[0;31m        bs = flattened_fs - jnp.einsum(\n",
      "\u001b[0m\u001b[0;32m    184 \u001b[0;31m            \u001b[0;34m\"tij,tj->ti\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_As\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "(32, 5, 64, 5, 64)\n",
      "(32, 320, 320)\n",
      "*** AttributeError: module 'jax.numpy' has no attribute 'eig'\n",
      "*** AttributeError: module 'jax.numpy' has no attribute 'eigs'\n",
      "*** ValueError: Argument to nonsymmetric eigendecomposition must have shape [..., n, n], got shape (1, 5, 64, 5, 64)\n",
      "(Traced<ShapedArray(complex64[320])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
      "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]],      dtype=complex64)\n",
      "  batch_dim = 0, Traced<ShapedArray(complex64[320,320])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[[1.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 1.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 1.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        ...,\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 1.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 1.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 1.+0.j]]],      dtype=complex64)\n",
      "  batch_dim = 0)\n",
      "*** AttributeError: module 'jax.numpy.linalg' has no attribute 'eigs'. Did you mean: 'eig'?\n",
      "(Traced<ShapedArray(complex64[320])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[-1.09526222e+02+0.00000000e+00j, -5.52201271e+01+8.07480469e+01j,\n",
      "        -5.52201271e+01-8.07480469e+01j, -1.43282700e+01+9.66362534e+01j,\n",
      "        -1.43282700e+01-9.66362534e+01j,  4.01374207e+01+8.73355331e+01j,\n",
      "         4.01374207e+01-8.73355331e+01j,  6.84299164e+01+6.22889099e+01j,\n",
      "         6.84299164e+01-6.22889099e+01j,  8.13432999e+01+2.99468060e+01j,\n",
      "         8.13432999e+01-2.99468060e+01j,  1.94179764e+01+7.60701981e+01j,\n",
      "         1.94179764e+01-7.60701981e+01j, -4.41744995e+01+6.61751480e+01j,\n",
      "        -4.41744995e+01-6.61751480e+01j, -8.30572357e+01+0.00000000e+00j,\n",
      "        -7.94896927e+01+0.00000000e+00j, -6.12180862e+01+4.25843735e+01j,\n",
      "        -6.12180862e+01-4.25843735e+01j,  2.15495758e+01+6.27228966e+01j,\n",
      "         2.15495758e+01-6.27228966e+01j, -6.15302620e+01+1.89562569e+01j,\n",
      "        -6.15302620e+01-1.89562569e+01j,  5.43540115e+01+2.80805721e+01j,\n",
      "         5.43540115e+01-2.80805721e+01j,  5.53664398e+01+6.37350750e+00j,\n",
      "         5.53664398e+01-6.37350750e+00j,  3.77527847e+01+3.71090736e+01j,\n",
      "         3.77527847e+01-3.71090736e+01j, -5.42630234e+01+0.00000000e+00j,\n",
      "        -4.30707970e+01+2.80994358e+01j, -4.30707970e+01-2.80994358e+01j,\n",
      "        -1.87875938e+01+4.63541794e+01j, -1.87875938e+01-4.63541794e+01j,\n",
      "        -6.66412449e+00+4.83179970e+01j, -6.66412449e+00-4.83179970e+01j,\n",
      "        -2.71100540e+01+4.03739357e+01j, -2.71100540e+01-4.03739357e+01j,\n",
      "         2.05686455e+01+4.36677246e+01j,  2.05686455e+01-4.36677246e+01j,\n",
      "         5.10798836e+00+4.66339455e+01j,  5.10798836e+00-4.66339455e+01j,\n",
      "         3.47149696e+01+3.11445236e+01j,  3.47149696e+01-3.11445236e+01j,\n",
      "         4.11716309e+01+1.49733982e+01j,  4.11716309e+01-1.49733982e+01j,\n",
      "         4.00418167e+01+4.76895332e+00j,  4.00418167e+01-4.76895332e+00j,\n",
      "         1.02089405e+01+3.80351715e+01j,  1.02089405e+01-3.80351715e+01j,\n",
      "        -2.15872841e+01+3.30875969e+01j, -2.15872841e+01-3.30875969e+01j,\n",
      "         2.83501797e+01+2.41740017e+01j,  2.83501797e+01-2.41740017e+01j,\n",
      "        -4.10286331e+01+0.00000000e+00j, -3.92449265e+01+0.00000000e+00j,\n",
      "        -3.07890854e+01+2.03539486e+01j, -3.07890854e+01-2.03539486e+01j,\n",
      "        -3.01091347e+01+2.12922573e+01j, -3.01091347e+01-2.12922573e+01j,\n",
      "        -3.58419418e+01+0.00000000e+00j, -1.34159493e+00+3.40762787e+01j,\n",
      "        -1.34159493e+00-3.40762787e+01j, -3.02652206e+01+9.47811127e+00j,\n",
      "        -3.02652206e+01-9.47811127e+00j, -4.10941839e+00+3.22119942e+01j,\n",
      "        -4.10941839e+00-3.22119942e+01j, -1.77400208e+01+2.69159622e+01j,\n",
      "        -1.77400208e+01-2.69159622e+01j,  1.12748547e+01+3.13614826e+01j,\n",
      "         1.12748547e+01-3.13614826e+01j,  1.40457706e+01+2.91118011e+01j,\n",
      "         1.40457706e+01-2.91118011e+01j, -1.94677944e+01+2.25764523e+01j,\n",
      "        -1.94677944e+01-2.25764523e+01j,  2.34765511e+01+2.07629871e+01j,\n",
      "         2.34765511e+01-2.07629871e+01j,  1.16310654e+01+2.78578835e+01j,\n",
      "         1.16310654e+01-2.78578835e+01j,  2.76770096e+01+1.40402451e+01j,\n",
      "         2.76770096e+01-1.40402451e+01j,  3.06196957e+01+0.00000000e+00j,\n",
      "         2.77811508e+01+9.98229408e+00j,  2.77811508e+01-9.98229408e+00j,\n",
      "         2.81832123e+01+3.18673348e+00j,  2.81832123e+01-3.18673348e+00j,\n",
      "        -1.40581818e+01+2.20584641e+01j, -1.40581818e+01-2.20584641e+01j,\n",
      "        -2.10353374e+01+1.40497103e+01j, -2.10353374e+01-1.40497103e+01j,\n",
      "        -2.70190926e+01+0.00000000e+00j, -2.66315422e+01+0.00000000e+00j,\n",
      "        -2.58299751e+01+0.00000000e+00j,  1.93763790e+01+1.85545330e+01j,\n",
      "         1.93763790e+01-1.85545330e+01j,  7.13941431e+00+2.53566284e+01j,\n",
      "         7.13941431e+00-2.53566284e+01j,  1.78575096e+01+1.55721922e+01j,\n",
      "         1.78575096e+01-1.55721922e+01j,  1.07844210e+01+2.18339081e+01j,\n",
      "         1.07844210e+01-2.18339081e+01j, -8.89389229e+00+2.31770573e+01j,\n",
      "        -8.89389229e+00-2.31770573e+01j, -2.83205462e+00+2.41590805e+01j,\n",
      "        -2.83205462e+00-2.41590805e+01j,  3.05402946e+00+2.33169270e+01j,\n",
      "         3.05402946e+00-2.33169270e+01j, -1.30550232e+01+2.01870441e+01j,\n",
      "        -1.30550232e+01-2.01870441e+01j, -1.97394161e+01+1.41947832e+01j,\n",
      "        -1.97394161e+01-1.41947832e+01j,  7.84985590e+00+2.09076824e+01j,\n",
      "         7.84985590e+00-2.09076824e+01j, -1.98434429e+01+6.31878662e+00j,\n",
      "        -1.98434429e+01-6.31878662e+00j, -2.19004383e+01+0.00000000e+00j,\n",
      "        -2.11051998e+01+0.00000000e+00j,  2.10858727e+01+7.48667717e+00j,\n",
      "         2.10858727e+01-7.48667717e+00j,  1.84710789e+01+1.04788904e+01j,\n",
      "         1.84710789e+01-1.04788904e+01j,  1.87847252e+01+9.36015415e+00j,\n",
      "         1.87847252e+01-9.36015415e+00j,  2.05208626e+01+2.38436770e+00j,\n",
      "         2.05208626e+01-2.38436770e+00j,  5.60441637e+00+1.90176296e+01j,\n",
      "         5.60441637e+00-1.90176296e+01j,  8.82744503e+00+1.74671421e+01j,\n",
      "         8.82744503e+00-1.74671421e+01j, -2.06567097e+00+1.93272400e+01j,\n",
      "        -2.06567097e+00-1.93272400e+01j, -2.00142593e+01+0.00000000e+00j,\n",
      "        -1.91224499e+01+0.00000000e+00j, -1.02936602e+01+1.65438213e+01j,\n",
      "        -1.02936602e+01-1.65438213e+01j, -1.02440224e+01+1.61495972e+01j,\n",
      "        -1.02440224e+01-1.61495972e+01j, -1.48946304e+01+1.01770296e+01j,\n",
      "        -1.48946304e+01-1.01770296e+01j, -1.45545216e+01+1.06461592e+01j,\n",
      "        -1.45545216e+01-1.06461592e+01j, -1.36901455e+01+9.36633873e+00j,\n",
      "        -1.36901455e+01-9.36633873e+00j, -1.46327057e+01+4.73907661e+00j,\n",
      "        -1.46327057e+01-4.73907661e+00j, -1.58114815e+01+0.00000000e+00j,\n",
      "        -1.56054726e+01+0.00000000e+00j, -3.93705273e+00+1.67570953e+01j,\n",
      "        -3.93705273e+00-1.67570953e+01j, -5.59589481e+00+1.54514275e+01j,\n",
      "        -5.59589481e+00-1.54514275e+01j,  1.91221237e+01+2.12449455e+00j,\n",
      "         1.91221237e+01-2.12449455e+00j, -1.70947269e-01+1.70380936e+01j,\n",
      "        -1.70947269e-01-1.70380936e+01j,  1.70687103e+01+5.98938847e+00j,\n",
      "         1.70687103e+01-5.98938847e+00j,  1.46750889e+01+1.20870218e+01j,\n",
      "         1.46750889e+01-1.20870218e+01j,  1.44860411e+01+1.24578571e+01j,\n",
      "         1.44860411e+01-1.24578571e+01j,  1.32509975e+01+1.23698330e+01j,\n",
      "         1.32509975e+01-1.23698330e+01j,  6.13745022e+00+1.56807508e+01j,\n",
      "         6.13745022e+00-1.56807508e+01j,  2.36942697e+00+1.55447865e+01j,\n",
      "         2.36942697e+00-1.55447865e+01j,  1.43385525e+01+7.02020311e+00j,\n",
      "         1.43385525e+01-7.02020311e+00j, -8.03491211e+00+1.32350664e+01j,\n",
      "        -8.03491211e+00-1.32350664e+01j, -1.50979595e+01+0.00000000e+00j,\n",
      "         4.68363142e+00+1.52140598e+01j,  4.68363142e+00-1.52140598e+01j,\n",
      "         6.31543064e+00+1.39289389e+01j,  6.31543064e+00-1.39289389e+01j,\n",
      "        -9.23384666e+00+1.12882757e+01j, -9.23384666e+00-1.12882757e+01j,\n",
      "        -1.14437046e+01+8.51687717e+00j, -1.14437046e+01-8.51687717e+00j,\n",
      "         1.58101816e+01+0.00000000e+00j,  5.10993576e+00+1.25445805e+01j,\n",
      "         5.10993576e+00-1.25445805e+01j, -3.94691181e+00+1.15886555e+01j,\n",
      "        -3.94691181e+00-1.15886555e+01j, -1.15060549e+01+3.79125285e+00j,\n",
      "        -1.15060549e+01-3.79125285e+00j, -1.00178738e+01+7.02500820e+00j,\n",
      "        -1.00178738e+01-7.02500820e+00j, -9.59653759e+00+6.78476620e+00j,\n",
      "        -9.59653759e+00-6.78476620e+00j, -1.04501686e+01+0.00000000e+00j,\n",
      "         2.02698755e+00+1.16583424e+01j,  2.02698755e+00-1.16583424e+01j,\n",
      "         2.19531715e-01+1.13587265e+01j,  2.19531715e-01-1.13587265e+01j,\n",
      "         1.01881332e+01+9.27719784e+00j,  1.01881332e+01-9.27719784e+00j,\n",
      "         1.45915642e+01+1.59338427e+00j,  1.45915642e+01-1.59338427e+00j,\n",
      "         1.40141687e+01+1.58986473e+00j,  1.40141687e+01-1.58986473e+00j,\n",
      "         1.01166134e+01+8.05799007e+00j,  1.01166134e+01-8.05799007e+00j,\n",
      "         1.16708088e+01+5.61609650e+00j,  1.16708088e+01-5.61609650e+00j,\n",
      "        -7.81410599e+00+5.61977482e+00j, -7.81410599e+00-5.61977482e+00j,\n",
      "        -2.95755959e+00+9.27083302e+00j, -2.95755959e+00-9.27083302e+00j,\n",
      "        -5.82257843e+00+7.52545547e+00j, -5.82257843e+00-7.52545547e+00j,\n",
      "         4.54384422e+00+9.28581905e+00j,  4.54384422e+00-9.28581905e+00j,\n",
      "         8.35062122e+00+7.42188168e+00j,  8.35062122e+00-7.42188168e+00j,\n",
      "         1.82163739e+00+9.32686329e+00j,  1.82163739e+00-9.32686329e+00j,\n",
      "        -6.94706249e+00+5.08834076e+00j, -6.94706249e+00-5.08834076e+00j,\n",
      "         4.14552808e-01+8.51906967e+00j,  4.14552808e-01-8.51906967e+00j,\n",
      "        -1.46842027e+00+8.37871170e+00j, -1.46842027e+00-8.37871170e+00j,\n",
      "        -7.30272341e+00+0.00000000e+00j, -6.63351250e+00+0.00000000e+00j,\n",
      "         9.73550129e+00+5.23967361e+00j,  9.73550129e+00-5.23967361e+00j,\n",
      "         1.10021076e+01+2.92305255e+00j,  1.10021076e+01-2.92305255e+00j,\n",
      "         7.83756924e+00+6.04347038e+00j,  7.83756924e+00-6.04347038e+00j,\n",
      "        -4.19307566e+00+6.36828852e+00j, -4.19307566e+00-6.36828852e+00j,\n",
      "        -5.35791206e+00+4.07091188e+00j, -5.35791206e+00-4.07091188e+00j,\n",
      "        -4.11699057e+00+5.64413548e+00j, -4.11699057e+00-5.64413548e+00j,\n",
      "         1.18733044e+01+1.27469563e+00j,  1.18733044e+01-1.27469563e+00j,\n",
      "         1.08729401e+01+0.00000000e+00j,  1.07603455e+01+1.19210398e+00j,\n",
      "         1.07603455e+01-1.19210398e+00j,  9.96302414e+00+3.59495938e-01j,\n",
      "         9.96302414e+00-3.59495938e-01j,  3.65772772e+00+6.96458006e+00j,\n",
      "         3.65772772e+00-6.96458006e+00j,  5.31695068e-01+6.81527042e+00j,\n",
      "         5.31695068e-01-6.81527042e+00j, -3.09355116e+00+4.51527357e+00j,\n",
      "        -3.09355116e+00-4.51527357e+00j, -4.72503805e+00+0.00000000e+00j,\n",
      "        -4.53499269e+00+0.00000000e+00j,  6.82360601e+00+3.49274611e+00j,\n",
      "         6.82360601e+00-3.49274611e+00j,  8.80840111e+00+9.53795075e-01j,\n",
      "         8.80840111e+00-9.53795075e-01j, -6.45786822e-01+5.58560848e+00j,\n",
      "        -6.45786822e-01-5.58560848e+00j,  3.12616491e+00+5.57150602e+00j,\n",
      "         3.12616491e+00-5.57150602e+00j,  6.47003460e+00+4.83483505e+00j,\n",
      "         6.47003460e+00-4.83483505e+00j,  8.40497875e+00+0.00000000e+00j,\n",
      "         6.92395639e+00+0.00000000e+00j,  5.36783218e+00+2.61986113e+00j,\n",
      "         5.36783218e+00-2.61986113e+00j,  6.00135994e+00+1.46143973e+00j,\n",
      "         6.00135994e+00-1.46143973e+00j, -2.34150484e-01+4.18936586e+00j,\n",
      "        -2.34150484e-01-4.18936586e+00j, -1.59645057e+00+3.18411493e+00j,\n",
      "        -1.59645057e+00-3.18411493e+00j,  1.25650400e-02+3.35141182e+00j,\n",
      "         1.25650400e-02-3.35141182e+00j, -3.58010268e+00+0.00000000e+00j,\n",
      "        -3.15165377e+00+0.00000000e+00j, -7.31103182e-01+2.12277961e+00j,\n",
      "        -7.31103182e-01-2.12277961e+00j, -2.32097173e+00+0.00000000e+00j,\n",
      "        -1.33983171e+00+0.00000000e+00j, -2.98159748e-01+1.59200633e+00j,\n",
      "        -2.98159748e-01-1.59200633e+00j,  4.49417114e+00+2.09577584e+00j,\n",
      "         4.49417114e+00-2.09577584e+00j,  5.48141909e+00+1.79532394e-01j,\n",
      "         5.48141909e+00-1.79532394e-01j,  4.33352900e+00+9.74671900e-01j,\n",
      "         4.33352900e+00-9.74671900e-01j,  3.98796463e+00+1.21271916e-01j,\n",
      "         3.98796463e+00-1.21271916e-01j,  3.50094795e+00+7.30629385e-01j,\n",
      "         3.50094795e+00-7.30629385e-01j, -3.86317000e-02+1.27370036e+00j,\n",
      "        -3.86317000e-02-1.27370036e+00j,  2.23428154e+00+1.30440295e+00j,\n",
      "         2.23428154e+00-1.30440295e+00j,  3.00033164e+00+5.84708452e-01j,\n",
      "         3.00033164e+00-5.84708452e-01j,  3.24057913e+00+8.89421925e-02j,\n",
      "         3.24057913e+00-8.89421925e-02j,  2.79260945e+00+7.15804175e-02j,\n",
      "         2.79260945e+00-7.15804175e-02j, -1.70531973e-01+0.00000000e+00j,\n",
      "         1.61697555e+00+6.52520955e-01j,  1.61697555e+00-6.52520955e-01j,\n",
      "         3.67746763e-02+0.00000000e+00j,  1.41154671e+00+4.34872329e-01j,\n",
      "         1.41154671e+00-4.34872329e-01j,  2.20668212e-01+0.00000000e+00j,\n",
      "         1.30842328e+00+3.26269180e-01j,  1.30842328e+00-3.26269180e-01j,\n",
      "         1.24691951e+00+2.60816276e-01j,  1.24691951e+00-2.60816276e-01j,\n",
      "         4.14722800e-01+0.00000000e+00j,  5.18979251e-01+0.00000000e+00j,\n",
      "         5.32019973e-01+0.00000000e+00j,  6.78311229e-01+0.00000000e+00j,\n",
      "         7.59502470e-01+0.00000000e+00j,  8.07349980e-01+0.00000000e+00j]],      dtype=complex64)\n",
      "  batch_dim = 0, Traced<ShapedArray(complex64[320,320])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[[ 8.17518607e-02+0.j        , -6.65270677e-03-0.00222336j,\n",
      "         -6.65270677e-03+0.00222336j, ..., -1.68022689e-06+0.j        ,\n",
      "         -6.45141199e-07+0.j        ,  3.10174016e-07+0.j        ],\n",
      "        [-4.87684794e-02+0.j        ,  6.58633485e-02-0.00804538j,\n",
      "          6.58633485e-02+0.00804538j, ...,  8.74048965e-06+0.j        ,\n",
      "          4.93760308e-06+0.j        , -3.88730996e-06+0.j        ],\n",
      "        [ 5.70588931e-02+0.j        ,  2.64817290e-02-0.0032441j ,\n",
      "          2.64817290e-02+0.0032441j , ...,  6.09302560e-07+0.j        ,\n",
      "          8.99512713e-08+0.j        ,  1.42081362e-07+0.j        ],\n",
      "        ...,\n",
      "        [-1.60142779e-02+0.j        , -3.73331420e-02+0.0121568j ,\n",
      "         -3.73331420e-02-0.0121568j , ..., -9.05099213e-02+0.j        ,\n",
      "         -9.93650630e-02+0.j        ,  1.02397986e-01+0.j        ],\n",
      "        [ 3.33538167e-02+0.j        , -2.21261801e-03-0.01381439j,\n",
      "         -2.21261801e-03+0.01381439j, ..., -1.38339221e-01+0.j        ,\n",
      "         -1.51882023e-01+0.j        ,  1.56523839e-01+0.j        ],\n",
      "        [-2.20453069e-02+0.j        , -2.06024051e-02-0.00300146j,\n",
      "         -2.06024051e-02+0.00300146j, ..., -5.07398658e-02+0.j        ,\n",
      "         -5.57052828e-02+0.j        ,  5.74057177e-02+0.j        ]]],      dtype=complex64)\n",
      "  batch_dim = 0)\n",
      "\u001b[1;32m    177 \u001b[0m        \u001b[0mflattened_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    178 \u001b[0m        flattened_As = jnp.reshape(\n",
      "\u001b[1;32m    179 \u001b[0m            \u001b[0mAs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    180 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    181 \u001b[0m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 182 \u001b[0;31m        \u001b[0mflattened_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    183 \u001b[0m        bs = flattened_fs - jnp.einsum(\n",
      "\u001b[1;32m    184 \u001b[0m            \u001b[0;34m\"tij,tj->ti\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_As\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    185 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    186 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    187 \u001b[0m        \u001b[0;31m# finally ready to evaluate linearized dynamics (in parallel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m    158 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    159 \u001b[0m        \"\"\"\n",
      "\u001b[1;32m    160 \u001b[0m        \u001b[0mThis\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mdeer\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwill\u001b[0m \u001b[0meventually\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msequential\u001b[0m \u001b[0mscanned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    161 \u001b[0m        \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    162 \u001b[0m          \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mnum_layers\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mshaped\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    163 \u001b[0m          \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    164 \u001b[0m        \"\"\"\n",
      "\u001b[1;32m    165 \u001b[0m        \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# length num_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    166 \u001b[0m        fs = jnp.array(\n",
      "\u001b[1;32m    167 \u001b[0m            \u001b[0mjtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    168 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T,D) arrays, note that we keep states as a list so we can use jtu.tree_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    169 \u001b[0m        As = jnp.array(\n",
      "\u001b[1;32m    170 \u001b[0m            \u001b[0mjtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacrev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    171 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T, D, T, D) tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    172 \u001b[0m        \u001b[0mAs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    173 \u001b[0m        \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    174 \u001b[0m        \u001b[0;31m# need to make the first A equal to zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    175 \u001b[0m        \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T,D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    176 \u001b[0m        \u001b[0;31m# do some rearranging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    177 \u001b[0m        \u001b[0mflattened_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    178 \u001b[0m        flattened_As = jnp.reshape(\n",
      "\u001b[1;32m    179 \u001b[0m            \u001b[0mAs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    180 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    181 \u001b[0m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 182 \u001b[0;31m        \u001b[0mflattened_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    183 \u001b[0m        bs = flattened_fs - jnp.einsum(\n",
      "\u001b[1;32m    184 \u001b[0m            \u001b[0;34m\"tij,tj->ti\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_As\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    185 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    186 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    187 \u001b[0m        \u001b[0;31m# finally ready to evaluate linearized dynamics (in parallel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    188 \u001b[0m        _, new_states = jax.lax.associative_scan(\n",
      "\u001b[1;32m    189 \u001b[0m            \u001b[0mbinary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflattened_As\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    190 \u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# parallel operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    191 \u001b[0m        \u001b[0;31m# new_states = jnp.nan_to_num(new_states)  # zero out nans, (num_layers, T*D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    192 \u001b[0m        \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_layers, T, D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    193 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    194 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "(320, 320)\n",
      "(Traced<ShapedArray(complex64[320])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[-1.09526222e+02+0.00000000e+00j, -5.52201271e+01+8.07480469e+01j,\n",
      "        -5.52201271e+01-8.07480469e+01j, -1.43282700e+01+9.66362534e+01j,\n",
      "        -1.43282700e+01-9.66362534e+01j,  4.01374207e+01+8.73355331e+01j,\n",
      "         4.01374207e+01-8.73355331e+01j,  6.84299164e+01+6.22889099e+01j,\n",
      "         6.84299164e+01-6.22889099e+01j,  8.13432999e+01+2.99468060e+01j,\n",
      "         8.13432999e+01-2.99468060e+01j,  1.94179764e+01+7.60701981e+01j,\n",
      "         1.94179764e+01-7.60701981e+01j, -4.41744995e+01+6.61751480e+01j,\n",
      "        -4.41744995e+01-6.61751480e+01j, -8.30572357e+01+0.00000000e+00j,\n",
      "        -7.94896927e+01+0.00000000e+00j, -6.12180862e+01+4.25843735e+01j,\n",
      "        -6.12180862e+01-4.25843735e+01j,  2.15495758e+01+6.27228966e+01j,\n",
      "         2.15495758e+01-6.27228966e+01j, -6.15302620e+01+1.89562569e+01j,\n",
      "        -6.15302620e+01-1.89562569e+01j,  5.43540115e+01+2.80805721e+01j,\n",
      "         5.43540115e+01-2.80805721e+01j,  5.53664398e+01+6.37350750e+00j,\n",
      "         5.53664398e+01-6.37350750e+00j,  3.77527847e+01+3.71090736e+01j,\n",
      "         3.77527847e+01-3.71090736e+01j, -5.42630234e+01+0.00000000e+00j,\n",
      "        -4.30707970e+01+2.80994358e+01j, -4.30707970e+01-2.80994358e+01j,\n",
      "        -1.87875938e+01+4.63541794e+01j, -1.87875938e+01-4.63541794e+01j,\n",
      "        -6.66412449e+00+4.83179970e+01j, -6.66412449e+00-4.83179970e+01j,\n",
      "        -2.71100540e+01+4.03739357e+01j, -2.71100540e+01-4.03739357e+01j,\n",
      "         2.05686455e+01+4.36677246e+01j,  2.05686455e+01-4.36677246e+01j,\n",
      "         5.10798836e+00+4.66339455e+01j,  5.10798836e+00-4.66339455e+01j,\n",
      "         3.47149696e+01+3.11445236e+01j,  3.47149696e+01-3.11445236e+01j,\n",
      "         4.11716309e+01+1.49733982e+01j,  4.11716309e+01-1.49733982e+01j,\n",
      "         4.00418167e+01+4.76895332e+00j,  4.00418167e+01-4.76895332e+00j,\n",
      "         1.02089405e+01+3.80351715e+01j,  1.02089405e+01-3.80351715e+01j,\n",
      "        -2.15872841e+01+3.30875969e+01j, -2.15872841e+01-3.30875969e+01j,\n",
      "         2.83501797e+01+2.41740017e+01j,  2.83501797e+01-2.41740017e+01j,\n",
      "        -4.10286331e+01+0.00000000e+00j, -3.92449265e+01+0.00000000e+00j,\n",
      "        -3.07890854e+01+2.03539486e+01j, -3.07890854e+01-2.03539486e+01j,\n",
      "        -3.01091347e+01+2.12922573e+01j, -3.01091347e+01-2.12922573e+01j,\n",
      "        -3.58419418e+01+0.00000000e+00j, -1.34159493e+00+3.40762787e+01j,\n",
      "        -1.34159493e+00-3.40762787e+01j, -3.02652206e+01+9.47811127e+00j,\n",
      "        -3.02652206e+01-9.47811127e+00j, -4.10941839e+00+3.22119942e+01j,\n",
      "        -4.10941839e+00-3.22119942e+01j, -1.77400208e+01+2.69159622e+01j,\n",
      "        -1.77400208e+01-2.69159622e+01j,  1.12748547e+01+3.13614826e+01j,\n",
      "         1.12748547e+01-3.13614826e+01j,  1.40457706e+01+2.91118011e+01j,\n",
      "         1.40457706e+01-2.91118011e+01j, -1.94677944e+01+2.25764523e+01j,\n",
      "        -1.94677944e+01-2.25764523e+01j,  2.34765511e+01+2.07629871e+01j,\n",
      "         2.34765511e+01-2.07629871e+01j,  1.16310654e+01+2.78578835e+01j,\n",
      "         1.16310654e+01-2.78578835e+01j,  2.76770096e+01+1.40402451e+01j,\n",
      "         2.76770096e+01-1.40402451e+01j,  3.06196957e+01+0.00000000e+00j,\n",
      "         2.77811508e+01+9.98229408e+00j,  2.77811508e+01-9.98229408e+00j,\n",
      "         2.81832123e+01+3.18673348e+00j,  2.81832123e+01-3.18673348e+00j,\n",
      "        -1.40581818e+01+2.20584641e+01j, -1.40581818e+01-2.20584641e+01j,\n",
      "        -2.10353374e+01+1.40497103e+01j, -2.10353374e+01-1.40497103e+01j,\n",
      "        -2.70190926e+01+0.00000000e+00j, -2.66315422e+01+0.00000000e+00j,\n",
      "        -2.58299751e+01+0.00000000e+00j,  1.93763790e+01+1.85545330e+01j,\n",
      "         1.93763790e+01-1.85545330e+01j,  7.13941431e+00+2.53566284e+01j,\n",
      "         7.13941431e+00-2.53566284e+01j,  1.78575096e+01+1.55721922e+01j,\n",
      "         1.78575096e+01-1.55721922e+01j,  1.07844210e+01+2.18339081e+01j,\n",
      "         1.07844210e+01-2.18339081e+01j, -8.89389229e+00+2.31770573e+01j,\n",
      "        -8.89389229e+00-2.31770573e+01j, -2.83205462e+00+2.41590805e+01j,\n",
      "        -2.83205462e+00-2.41590805e+01j,  3.05402946e+00+2.33169270e+01j,\n",
      "         3.05402946e+00-2.33169270e+01j, -1.30550232e+01+2.01870441e+01j,\n",
      "        -1.30550232e+01-2.01870441e+01j, -1.97394161e+01+1.41947832e+01j,\n",
      "        -1.97394161e+01-1.41947832e+01j,  7.84985590e+00+2.09076824e+01j,\n",
      "         7.84985590e+00-2.09076824e+01j, -1.98434429e+01+6.31878662e+00j,\n",
      "        -1.98434429e+01-6.31878662e+00j, -2.19004383e+01+0.00000000e+00j,\n",
      "        -2.11051998e+01+0.00000000e+00j,  2.10858727e+01+7.48667717e+00j,\n",
      "         2.10858727e+01-7.48667717e+00j,  1.84710789e+01+1.04788904e+01j,\n",
      "         1.84710789e+01-1.04788904e+01j,  1.87847252e+01+9.36015415e+00j,\n",
      "         1.87847252e+01-9.36015415e+00j,  2.05208626e+01+2.38436770e+00j,\n",
      "         2.05208626e+01-2.38436770e+00j,  5.60441637e+00+1.90176296e+01j,\n",
      "         5.60441637e+00-1.90176296e+01j,  8.82744503e+00+1.74671421e+01j,\n",
      "         8.82744503e+00-1.74671421e+01j, -2.06567097e+00+1.93272400e+01j,\n",
      "        -2.06567097e+00-1.93272400e+01j, -2.00142593e+01+0.00000000e+00j,\n",
      "        -1.91224499e+01+0.00000000e+00j, -1.02936602e+01+1.65438213e+01j,\n",
      "        -1.02936602e+01-1.65438213e+01j, -1.02440224e+01+1.61495972e+01j,\n",
      "        -1.02440224e+01-1.61495972e+01j, -1.48946304e+01+1.01770296e+01j,\n",
      "        -1.48946304e+01-1.01770296e+01j, -1.45545216e+01+1.06461592e+01j,\n",
      "        -1.45545216e+01-1.06461592e+01j, -1.36901455e+01+9.36633873e+00j,\n",
      "        -1.36901455e+01-9.36633873e+00j, -1.46327057e+01+4.73907661e+00j,\n",
      "        -1.46327057e+01-4.73907661e+00j, -1.58114815e+01+0.00000000e+00j,\n",
      "        -1.56054726e+01+0.00000000e+00j, -3.93705273e+00+1.67570953e+01j,\n",
      "        -3.93705273e+00-1.67570953e+01j, -5.59589481e+00+1.54514275e+01j,\n",
      "        -5.59589481e+00-1.54514275e+01j,  1.91221237e+01+2.12449455e+00j,\n",
      "         1.91221237e+01-2.12449455e+00j, -1.70947269e-01+1.70380936e+01j,\n",
      "        -1.70947269e-01-1.70380936e+01j,  1.70687103e+01+5.98938847e+00j,\n",
      "         1.70687103e+01-5.98938847e+00j,  1.46750889e+01+1.20870218e+01j,\n",
      "         1.46750889e+01-1.20870218e+01j,  1.44860411e+01+1.24578571e+01j,\n",
      "         1.44860411e+01-1.24578571e+01j,  1.32509975e+01+1.23698330e+01j,\n",
      "         1.32509975e+01-1.23698330e+01j,  6.13745022e+00+1.56807508e+01j,\n",
      "         6.13745022e+00-1.56807508e+01j,  2.36942697e+00+1.55447865e+01j,\n",
      "         2.36942697e+00-1.55447865e+01j,  1.43385525e+01+7.02020311e+00j,\n",
      "         1.43385525e+01-7.02020311e+00j, -8.03491211e+00+1.32350664e+01j,\n",
      "        -8.03491211e+00-1.32350664e+01j, -1.50979595e+01+0.00000000e+00j,\n",
      "         4.68363142e+00+1.52140598e+01j,  4.68363142e+00-1.52140598e+01j,\n",
      "         6.31543064e+00+1.39289389e+01j,  6.31543064e+00-1.39289389e+01j,\n",
      "        -9.23384666e+00+1.12882757e+01j, -9.23384666e+00-1.12882757e+01j,\n",
      "        -1.14437046e+01+8.51687717e+00j, -1.14437046e+01-8.51687717e+00j,\n",
      "         1.58101816e+01+0.00000000e+00j,  5.10993576e+00+1.25445805e+01j,\n",
      "         5.10993576e+00-1.25445805e+01j, -3.94691181e+00+1.15886555e+01j,\n",
      "        -3.94691181e+00-1.15886555e+01j, -1.15060549e+01+3.79125285e+00j,\n",
      "        -1.15060549e+01-3.79125285e+00j, -1.00178738e+01+7.02500820e+00j,\n",
      "        -1.00178738e+01-7.02500820e+00j, -9.59653759e+00+6.78476620e+00j,\n",
      "        -9.59653759e+00-6.78476620e+00j, -1.04501686e+01+0.00000000e+00j,\n",
      "         2.02698755e+00+1.16583424e+01j,  2.02698755e+00-1.16583424e+01j,\n",
      "         2.19531715e-01+1.13587265e+01j,  2.19531715e-01-1.13587265e+01j,\n",
      "         1.01881332e+01+9.27719784e+00j,  1.01881332e+01-9.27719784e+00j,\n",
      "         1.45915642e+01+1.59338427e+00j,  1.45915642e+01-1.59338427e+00j,\n",
      "         1.40141687e+01+1.58986473e+00j,  1.40141687e+01-1.58986473e+00j,\n",
      "         1.01166134e+01+8.05799007e+00j,  1.01166134e+01-8.05799007e+00j,\n",
      "         1.16708088e+01+5.61609650e+00j,  1.16708088e+01-5.61609650e+00j,\n",
      "        -7.81410599e+00+5.61977482e+00j, -7.81410599e+00-5.61977482e+00j,\n",
      "        -2.95755959e+00+9.27083302e+00j, -2.95755959e+00-9.27083302e+00j,\n",
      "        -5.82257843e+00+7.52545547e+00j, -5.82257843e+00-7.52545547e+00j,\n",
      "         4.54384422e+00+9.28581905e+00j,  4.54384422e+00-9.28581905e+00j,\n",
      "         8.35062122e+00+7.42188168e+00j,  8.35062122e+00-7.42188168e+00j,\n",
      "         1.82163739e+00+9.32686329e+00j,  1.82163739e+00-9.32686329e+00j,\n",
      "        -6.94706249e+00+5.08834076e+00j, -6.94706249e+00-5.08834076e+00j,\n",
      "         4.14552808e-01+8.51906967e+00j,  4.14552808e-01-8.51906967e+00j,\n",
      "        -1.46842027e+00+8.37871170e+00j, -1.46842027e+00-8.37871170e+00j,\n",
      "        -7.30272341e+00+0.00000000e+00j, -6.63351250e+00+0.00000000e+00j,\n",
      "         9.73550129e+00+5.23967361e+00j,  9.73550129e+00-5.23967361e+00j,\n",
      "         1.10021076e+01+2.92305255e+00j,  1.10021076e+01-2.92305255e+00j,\n",
      "         7.83756924e+00+6.04347038e+00j,  7.83756924e+00-6.04347038e+00j,\n",
      "        -4.19307566e+00+6.36828852e+00j, -4.19307566e+00-6.36828852e+00j,\n",
      "        -5.35791206e+00+4.07091188e+00j, -5.35791206e+00-4.07091188e+00j,\n",
      "        -4.11699057e+00+5.64413548e+00j, -4.11699057e+00-5.64413548e+00j,\n",
      "         1.18733044e+01+1.27469563e+00j,  1.18733044e+01-1.27469563e+00j,\n",
      "         1.08729401e+01+0.00000000e+00j,  1.07603455e+01+1.19210398e+00j,\n",
      "         1.07603455e+01-1.19210398e+00j,  9.96302414e+00+3.59495938e-01j,\n",
      "         9.96302414e+00-3.59495938e-01j,  3.65772772e+00+6.96458006e+00j,\n",
      "         3.65772772e+00-6.96458006e+00j,  5.31695068e-01+6.81527042e+00j,\n",
      "         5.31695068e-01-6.81527042e+00j, -3.09355116e+00+4.51527357e+00j,\n",
      "        -3.09355116e+00-4.51527357e+00j, -4.72503805e+00+0.00000000e+00j,\n",
      "        -4.53499269e+00+0.00000000e+00j,  6.82360601e+00+3.49274611e+00j,\n",
      "         6.82360601e+00-3.49274611e+00j,  8.80840111e+00+9.53795075e-01j,\n",
      "         8.80840111e+00-9.53795075e-01j, -6.45786822e-01+5.58560848e+00j,\n",
      "        -6.45786822e-01-5.58560848e+00j,  3.12616491e+00+5.57150602e+00j,\n",
      "         3.12616491e+00-5.57150602e+00j,  6.47003460e+00+4.83483505e+00j,\n",
      "         6.47003460e+00-4.83483505e+00j,  8.40497875e+00+0.00000000e+00j,\n",
      "         6.92395639e+00+0.00000000e+00j,  5.36783218e+00+2.61986113e+00j,\n",
      "         5.36783218e+00-2.61986113e+00j,  6.00135994e+00+1.46143973e+00j,\n",
      "         6.00135994e+00-1.46143973e+00j, -2.34150484e-01+4.18936586e+00j,\n",
      "        -2.34150484e-01-4.18936586e+00j, -1.59645057e+00+3.18411493e+00j,\n",
      "        -1.59645057e+00-3.18411493e+00j,  1.25650400e-02+3.35141182e+00j,\n",
      "         1.25650400e-02-3.35141182e+00j, -3.58010268e+00+0.00000000e+00j,\n",
      "        -3.15165377e+00+0.00000000e+00j, -7.31103182e-01+2.12277961e+00j,\n",
      "        -7.31103182e-01-2.12277961e+00j, -2.32097173e+00+0.00000000e+00j,\n",
      "        -1.33983171e+00+0.00000000e+00j, -2.98159748e-01+1.59200633e+00j,\n",
      "        -2.98159748e-01-1.59200633e+00j,  4.49417114e+00+2.09577584e+00j,\n",
      "         4.49417114e+00-2.09577584e+00j,  5.48141909e+00+1.79532394e-01j,\n",
      "         5.48141909e+00-1.79532394e-01j,  4.33352900e+00+9.74671900e-01j,\n",
      "         4.33352900e+00-9.74671900e-01j,  3.98796463e+00+1.21271916e-01j,\n",
      "         3.98796463e+00-1.21271916e-01j,  3.50094795e+00+7.30629385e-01j,\n",
      "         3.50094795e+00-7.30629385e-01j, -3.86317000e-02+1.27370036e+00j,\n",
      "        -3.86317000e-02-1.27370036e+00j,  2.23428154e+00+1.30440295e+00j,\n",
      "         2.23428154e+00-1.30440295e+00j,  3.00033164e+00+5.84708452e-01j,\n",
      "         3.00033164e+00-5.84708452e-01j,  3.24057913e+00+8.89421925e-02j,\n",
      "         3.24057913e+00-8.89421925e-02j,  2.79260945e+00+7.15804175e-02j,\n",
      "         2.79260945e+00-7.15804175e-02j, -1.70531973e-01+0.00000000e+00j,\n",
      "         1.61697555e+00+6.52520955e-01j,  1.61697555e+00-6.52520955e-01j,\n",
      "         3.67746763e-02+0.00000000e+00j,  1.41154671e+00+4.34872329e-01j,\n",
      "         1.41154671e+00-4.34872329e-01j,  2.20668212e-01+0.00000000e+00j,\n",
      "         1.30842328e+00+3.26269180e-01j,  1.30842328e+00-3.26269180e-01j,\n",
      "         1.24691951e+00+2.60816276e-01j,  1.24691951e+00-2.60816276e-01j,\n",
      "         4.14722800e-01+0.00000000e+00j,  5.18979251e-01+0.00000000e+00j,\n",
      "         5.32019973e-01+0.00000000e+00j,  6.78311229e-01+0.00000000e+00j,\n",
      "         7.59502470e-01+0.00000000e+00j,  8.07349980e-01+0.00000000e+00j]],      dtype=complex64)\n",
      "  batch_dim = 0, Traced<ShapedArray(complex64[320,320])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[[ 8.17518607e-02+0.j        , -6.65270677e-03-0.00222336j,\n",
      "         -6.65270677e-03+0.00222336j, ..., -1.68022689e-06+0.j        ,\n",
      "         -6.45141199e-07+0.j        ,  3.10174016e-07+0.j        ],\n",
      "        [-4.87684794e-02+0.j        ,  6.58633485e-02-0.00804538j,\n",
      "          6.58633485e-02+0.00804538j, ...,  8.74048965e-06+0.j        ,\n",
      "          4.93760308e-06+0.j        , -3.88730996e-06+0.j        ],\n",
      "        [ 5.70588931e-02+0.j        ,  2.64817290e-02-0.0032441j ,\n",
      "          2.64817290e-02+0.0032441j , ...,  6.09302560e-07+0.j        ,\n",
      "          8.99512713e-08+0.j        ,  1.42081362e-07+0.j        ],\n",
      "        ...,\n",
      "        [-1.60142779e-02+0.j        , -3.73331420e-02+0.0121568j ,\n",
      "         -3.73331420e-02-0.0121568j , ..., -9.05099213e-02+0.j        ,\n",
      "         -9.93650630e-02+0.j        ,  1.02397986e-01+0.j        ],\n",
      "        [ 3.33538167e-02+0.j        , -2.21261801e-03-0.01381439j,\n",
      "         -2.21261801e-03+0.01381439j, ..., -1.38339221e-01+0.j        ,\n",
      "         -1.51882023e-01+0.j        ,  1.56523839e-01+0.j        ],\n",
      "        [-2.20453069e-02+0.j        , -2.06024051e-02-0.00300146j,\n",
      "         -2.06024051e-02+0.00300146j, ..., -5.07398658e-02+0.j        ,\n",
      "         -5.57052828e-02+0.j        ,  5.74057177e-02+0.j        ]]],      dtype=complex64)\n",
      "  batch_dim = 0)\n",
      "*** TypeError: absolute requires ndarray or scalar arguments, got <class 'tuple'> at position 0.\n"
     ]
    }
   ],
   "source": [
    "# can we make it work on this example withou the kv cache?\n",
    "# set random seeds, try to get the same output with regular __call__ vs parallel_call\n",
    "fake_pos = jnp.array([0, 1, 2, 3, 4], dtype=jnp.int32)\n",
    "fake_inp = jnp.asarray([[1,  832,  349,  265, 1369]], dtype=jnp.int32)\n",
    "fake_mask = None\n",
    "\n",
    "# warmup\n",
    "logits = vmapped(fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3195ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 32000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4d45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b07b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp_flat = jnp.asarray([1, 832, 349, 265, 1369], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a00741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.10400391,  0.25585938,  0.43945312, ..., -0.61328125,\n",
       "        -0.37695312,  0.67578125],\n",
       "       [ 0.578125  ,  1.2734375 ,  0.2890625 , ...,  0.05419922,\n",
       "        -0.22363281,  0.3359375 ],\n",
       "       [ 0.19433594,  0.52734375, -0.3984375 , ..., -0.60546875,\n",
       "        -0.31445312, -0.31445312],\n",
       "       [-0.01696777,  1.1484375 , -0.36132812, ..., -0.66796875,\n",
       "         0.13378906, -0.08691406],\n",
       "       [-0.9375    ,  1.234375  ,  0.42382812, ...,  0.34570312,\n",
       "        -0.12890625,  0.02832031]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(fake_inp_flat, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b4f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 32000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b45669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp_flat = jnp.asarray([1, 832, 349, 265, 1369], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc5c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac0483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_embeddings(fake_inp_flat).shape # (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2421f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc248cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.compute_embeddings(fake_inp_flat)\n",
    "xq, xk, xv = attn.compute_qkv(x)\n",
    "key, value = attn.prefill(xk, xv)\n",
    "output = attn.compute_scores_and_output(xq, key, value, fake_mask, x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406da556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e23a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a4e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a71fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape # (T, n_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4f380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk.shape # (T, n_kv_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.shape # (T, n_kv_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.compute_scores_and_output(xq, xk, xv, fake_mask, 5).shape # (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5374a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_inp_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 96\u001b[0m, in \u001b[0;36mAttention.__call__\u001b[0;34m(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\u001b[0m\n\u001b[1;32m     93\u001b[0m xk \u001b[38;5;241m=\u001b[39m calculate_rope(xk, cos_freq, sin_freq, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# 3. Update cache\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m cache_k, cache_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_cache_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 4. Generation\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m positions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# prefill\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mAttention.update_cache_values\u001b[0;34m(self, xk, xv, cache_k, cache_v, positions)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_cache_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, xk, xv, cache_k, cache_v, positions):\n\u001b[0;32m---> 53\u001b[0m     cache_k \u001b[38;5;241m=\u001b[39m \u001b[43mcache_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mset(xk[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     54\u001b[0m     cache_v \u001b[38;5;241m=\u001b[39m cache_v\u001b[38;5;241m.\u001b[39mat[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mset(xv[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache_k, cache_v\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'at'"
     ]
    }
   ],
   "source": [
    "attn(model.compute_embeddings(fake_inp_flat), cos_freq[:5], sin_freq[:5], fake_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3410598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc44e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(model.compute_embeddings)(fake_inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 32000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # (batch, T, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a48e48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_inp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcos_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msin_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# x is of shape (seqlen, )\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     56\u001b[0m         seqlen \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/_module.py:1189\u001b[0m, in \u001b[0;36mPartial.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the wrapped `self.func`.\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m \n\u001b[1;32m   1179\u001b[0m \u001b[38;5;124;03m    **Arguments:**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03m    The result of the wrapped function.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mTransformer.compute_embeddings\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/nn/_embedding.py:101\u001b[0m, in \u001b[0;36mEmbedding.__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[x]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `jax.vmap` if you would like to index with multiple values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values."
     ]
    }
   ],
   "source": [
    "model(\n",
    "    fake_inp,\n",
    "    cos_freq[fake_pos],\n",
    "    sin_freq[fake_pos],\n",
    "    fake_pos,\n",
    "    fake_mask,\n",
    "    cache_k,\n",
    "    cache_v,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/nn/_embedding.py\u001b[0m(101)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m            raise ValueError(\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m                \u001b[0;34m\"`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    103 \u001b[0;31m                \u001b[0;34m\"Use `jax.vmap` if you would like to index with multiple values.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/contextlib.py\u001b[0m(81)\u001b[0;36minner\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     79 \u001b[0;31m        \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     80 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 81 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     82 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py\u001b[0m(24)\u001b[0;36mcompute_embeddings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     22 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 24 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31m    [... skipped 3 hidden frame(s)]\u001b[0m\n",
      "\n",
      "(1, 5)\n",
      "*** ValueError: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.\n",
      "*** ValueError: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.\n",
      "*** jax.errors.UnexpectedTracerError: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type int32[1,5] wrapped in a DynamicJaxprTracer to escape the scope of the transformation.\n",
      "JAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\n",
      "The function being traced when the value leaked was compute_embeddings at /Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/_jit.py:37 traced for jit.\n",
      "------------------------------\n",
      "The leaked intermediate value was created on line /var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py:53:12 (Transformer.__call__). \n",
      "------------------------------\n",
      "When the value was created, the final 5 stack frames (most recent last) excluding JAX-internal frames were:\n",
      "------------------------------\n",
      "<frozen runpy>:198:11 (_run_module_as_main)\n",
      "<frozen runpy>:88:4 (_run_code)\n",
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/1221483641.py:1 (<module>)\n",
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py:53:12 (Transformer.__call__)\n",
      "------------------------------\n",
      "\n",
      "To catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223d912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-eqx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
