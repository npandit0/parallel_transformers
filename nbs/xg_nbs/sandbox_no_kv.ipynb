{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20359b8e",
   "metadata": {},
   "source": [
    "# Model generation without the kv cache\n",
    "\n",
    "Let's see if we can get the code to work with turning the kv cache off.\n",
    "\n",
    "How the eigenvaleus be so large if you are using layer norm? In fact, the evals are large BECAUSE we are using RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4313c140-421d-4f1f-a283-3461b8db70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "from functools import partial\n",
    "from equinox._misc import default_floating_dtype\n",
    "from jaxtyping import Array, Float, Scalar\n",
    "from typing import Optional, Tuple, List, NamedTuple\n",
    "\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a7657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672df14d-d052-403a-8b68-b94a6240abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CPU for torch\n",
    "device  = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7533de2e-9d14-411a-a55a-852cb62646c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_21551/2163712912.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "# Load the model dict, and check if any GPU is used\n",
    "# state_dict = torch.load(\"mistral-7B-v0.1/consolidated.00.pth\")\n",
    "# why is this so much faster on our computer??\n",
    "state_dict = torch.load(\n",
    "    \"/Users/xaviergonzalez/Desktop/xavier_folders/stanford/cs229s/mistral_jax/model_files/consolidated.00.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27c428-fd21-41a1-9a5c-99a966f5a2a3",
   "metadata": {},
   "source": [
    "# 1. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd26d27d-8e7e-46e9-ba8d-187a8a57a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self._model = SentencePieceProcessor(model_file=model_path)\n",
    "\n",
    "    @property\n",
    "    def eos_id(self) -> int:\n",
    "        return self._model.eos_id()\n",
    "\n",
    "    @property\n",
    "    def pad_id(self) -> int:\n",
    "        return self._model.pad_id()\n",
    "\n",
    "    def encode(self, s: str) -> List[int]:\n",
    "        return [self._model.bos_id(), *self._model.encode(s)]\n",
    "\n",
    "    def decode(self, t: List[int]) -> str:\n",
    "        return self._model.decode(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5aced-2da9-42df-900d-b9d11d5f45fa",
   "metadata": {},
   "source": [
    "# 2. RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431e5fa1-25dd-401a-abfb-1371f5f1b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_frequencies(dim, max_pos, theta=10000.0):\n",
    "    inv_freq = 1.0 / (\n",
    "        theta ** (jnp.arange(0, dim, 2, dtype=jnp.float32)[: (dim // 2)] / dim)\n",
    "    )\n",
    "    t = jnp.arange(0, max_pos, dtype=jnp.float32)\n",
    "    freqs = jnp.outer(t, inv_freq)\n",
    "    return jnp.cos(freqs), jnp.sin(freqs)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3,))\n",
    "def calculate_rope(x, cos_freq, sin_freq, offset=0):\n",
    "    # x shape  is [seqlen, num_heads, heads_dim]\n",
    "\n",
    "    # Get the sequence length\n",
    "    seqlen = x.shape[0]\n",
    "\n",
    "    # Get the corresponding positional embeddings\n",
    "    sin = sin_freq[offset : offset + seqlen, :]\n",
    "    cos = cos_freq[offset : offset + seqlen, :]\n",
    "\n",
    "    # Positional embeddings are 2D while our input is 3D\n",
    "    # if `num_heads` dimension is present in the inputs.\n",
    "    # We need to add another dimension to our positional embeddings\n",
    "    sin = sin[:, jnp.newaxis, :]\n",
    "    cos = cos[:, jnp.newaxis, :]\n",
    "\n",
    "    # Get the even-odd positions from the inputs\n",
    "    x1 = x[..., 0::2]\n",
    "    x2 = x[..., 1::2]\n",
    "\n",
    "    # Matmul with the rotation matrix\n",
    "    # [cos_nθ, -sin_nθ] [x1]\n",
    "    # [sin_nθ,  cos_nθ] [x2]\n",
    "    # => [x1 * cos_nθ - x2 * sin_nθ, x1 * sin_nθ + x2 * cos_nθ]\n",
    "    pos_embed = jnp.stack([x1 * cos - x2 * sin, x1 * sin + x2 * cos], axis=-1)\n",
    "    pos_embed = jax.lax.collapse(pos_embed, -2)\n",
    "    return pos_embed.astype(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1aa31-614e-4483-8599-c5f0b4623292",
   "metadata": {},
   "source": [
    "# 3. RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fbb2d-ce6f-4b1a-a198-e4f37fab93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(eqx.Module):\n",
    "    \"\"\"\n",
    "    Make the root mean square of the output to be 1.\n",
    "    \"\"\"\n",
    "    eps: float\n",
    "    weight: Float[Array, \"*shape\"]\n",
    "\n",
    "    def __init__(self, dim, eps, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        self.eps = eps\n",
    "        self.weight = jnp.ones(shape=dim, dtype=dtype)\n",
    "\n",
    "    def rmsnorm(self, x):\n",
    "        return jnp.sqrt(jnp.mean(x**2, keepdims=True) + self.eps)\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * jax.lax.rsqrt(jnp.mean(x **2 , keepdims=True) + self.eps)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = self._norm(x.astype(jnp.float32)).astype(x.dtype)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f9a21-bb3c-45e8-805c-5f8605f72423",
   "metadata": {},
   "source": [
    "# 4. FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efffa74f-556b-4c3e-9f73-e23acfa1da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(eqx.Module):\n",
    "    w1: eqx.nn.Linear\n",
    "    w2: eqx.nn.Linear\n",
    "    w3: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "        self.w1 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.w2 = eqx.nn.Linear(args.hidden_dim, args.dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.w3 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = jax.nn.silu(self.w1(x).astype(jnp.float32)).astype(x.dtype)\n",
    "        return self.w2(h * self.w3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c459d5-b30d-48e5-924b-ea661542e8a2",
   "metadata": {},
   "source": [
    "# 5. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2048b724-3015-43c8-be5e-0214eb83af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    head_dim: int\n",
    "    n_kv_heads: int\n",
    "    kv_repeats: int\n",
    "    sliding_window: int\n",
    "    scale: float\n",
    "    wq: eqx.nn.Linear\n",
    "    wk: eqx.nn.Linear\n",
    "    wv: eqx.nn.Linear\n",
    "    wo: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.head_dim\n",
    "        self.n_kv_heads = args.n_kv_heads\n",
    "        self.dim = args.dim\n",
    "        self.kv_repeats = self.n_heads // self.n_kv_heads\n",
    "        self.sliding_window = args.sliding_window\n",
    "\n",
    "        self.scale = args.head_dim**-0.5\n",
    "\n",
    "        self.wq = eqx.nn.Linear(args.dim, args.n_heads * args.head_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.wk = eqx.nn.Linear(args.dim, args.n_kv_heads * args.head_dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.wv = eqx.nn.Linear(args.dim, args.n_kv_heads * args.head_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "        self.wo = eqx.nn.Linear(args.n_heads * args.head_dim, args.dim, use_bias=False, key=key4, dtype=dtype)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(2, 3))\n",
    "    def get_cache_slice(self, x, pos, kv_repeats):\n",
    "        x_slice = x.at[:pos, :, :].get()\n",
    "        x_slice = jnp.repeat(x_slice, kv_repeats, axis=1)\n",
    "        return x_slice\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_qkv(self, x):\n",
    "        seqlen, _ = x.shape\n",
    "\n",
    "        xq = jax.vmap(self.wq)(x)\n",
    "        xk = jax.vmap(self.wk)(x)\n",
    "        xv = jax.vmap(self.wv)(x)\n",
    "\n",
    "        xq = jnp.reshape(xq, (seqlen, self.n_heads, self.head_dim))\n",
    "        xk = jnp.reshape(xk, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        xv = jnp.reshape(xv, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        return xq, xk, xv\n",
    "\n",
    "    @jax.jit\n",
    "    def update_cache_values(self, xk, xv, cache_k, cache_v, positions):\n",
    "        cache_k = cache_k.at[positions, ...].set(xk[positions, ...])\n",
    "        cache_v = cache_v.at[positions, ...].set(xv[positions, ...])\n",
    "        return cache_k, cache_v\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def prefill(self, xk, xv):\n",
    "        key = jnp.repeat(xk, self.kv_repeats, axis=1)\n",
    "        value = jnp.repeat(xv, self.kv_repeats, axis=1)\n",
    "        return key, value\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_scores_and_output(self, xq, key, value, mask, seqlen):\n",
    "        query = jnp.transpose(xq, (1, 0, 2))\n",
    "        key = jnp.transpose(key, (1, 0, 2))\n",
    "        value = jnp.transpose(value, (1, 0, 2))\n",
    "\n",
    "        # # # scores : [n_heads, seqlen | 1, seqlen]\n",
    "        scores = jnp.matmul(query, jnp.transpose(key, (0, 2, 1))) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            # Mask will of shape [seqlen, seqlen] but our scores\n",
    "            # have shape [num_heads, seqlen, seqlen], hence we need\n",
    "            # to introduce another dimension in the mask\n",
    "            mask = mask[jnp.newaxis, ...]\n",
    "            scores = scores + mask\n",
    "\n",
    "        scores = jax.nn.softmax(scores.astype(jnp.float32), axis=-1).astype(query.dtype)\n",
    "        output = jnp.matmul(scores, value)\n",
    "        output = jnp.reshape(jnp.transpose(output, (1, 0, 2)), (seqlen, -1))\n",
    "        output = jax.vmap(self.wo)(output)\n",
    "        return output\n",
    "\n",
    "    def __call__(self,  x, cos_freq, sin_freq, positions, mask=None, cache_k=None, cache_v=None):\n",
    "        # x shape: [seqlen, embed_dim]\n",
    "        seqlen, _ = x.shape\n",
    "        # 1. Calculate qkv\n",
    "        xq, xk, xv = self.compute_qkv(x)\n",
    "\n",
    "        # 2. Calculate RoPE\n",
    "        xq = calculate_rope(xq, cos_freq, sin_freq, 0)\n",
    "        xk = calculate_rope(xk, cos_freq, sin_freq, 0)\n",
    "\n",
    "        key, value = self.prefill(xk, xv)\n",
    "\n",
    "        # # 3. Update cache\n",
    "        # cache_k, cache_v = self.update_cache_values(xk, xv, cache_k, cache_v, positions)\n",
    "\n",
    "        # # 4. Generation\n",
    "        # if positions.shape[0] > 1:\n",
    "        #     # prefill\n",
    "        #     key, value = self.prefill(xk, xv)\n",
    "        # else:\n",
    "        #     # single-token generation\n",
    "        #     cur_pos = positions[-1].item() + 1\n",
    "        #     key = self.get_cache_slice(cache_k, cur_pos, self.kv_repeats)\n",
    "        #     value = self.get_cache_slice(cache_v, cur_pos, self.kv_repeats)\n",
    "\n",
    "        # 5. Output\n",
    "        output = self.compute_scores_and_output(xq, key, value, mask, seqlen)\n",
    "        # return output, cache_k, cache_v\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a123d-c4b1-44f0-a6cd-5daf67c63adb",
   "metadata": {},
   "source": [
    "# 6. TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84cb56f-1a8f-4c28-9f3e-2c180f5e86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    attention: Attention\n",
    "    attention_norm: RMSNorm\n",
    "    feed_forward: FeedForward\n",
    "    ffn_norm: RMSNorm\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "\n",
    "        self.attention = Attention(args, key=key1, dtype=dtype)\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "        self.feed_forward = FeedForward(args, key=key2, dtype=dtype)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "    # def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask):\n",
    "        normed_x = jax.vmap(self.attention_norm)(x)\n",
    "        # r, cache_k, cache_v = self.attention(normed_x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\n",
    "        r = self.attention(\n",
    "            normed_x, cos_freq, sin_freq, positions, mask\n",
    "        )\n",
    "        h = x + r\n",
    "        r = jax.vmap(self.feed_forward)(jax.vmap(self.ffn_norm)(h))\n",
    "        out = h + r\n",
    "        return out\n",
    "        # return out, cache_k, cache_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f9502-010b-42ca-86ac-666e9476ff5c",
   "metadata": {},
   "source": [
    "# 7. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdec9a64-57c4-4fb5-8e8a-c3ecb4e5bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(eqx.Module):\n",
    "    tok_embeddings: eqx.nn.Embedding\n",
    "    layers: TransformerBlock\n",
    "    norm: RMSNorm\n",
    "    output: eqx.nn.Linear\n",
    "    vocab_size: int\n",
    "    n_layers: int\n",
    "    sliding_window: int\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        self.sliding_window = args.sliding_window\n",
    "        keys = jax.random.split(key, args.n_layers + 2)\n",
    "        embed_key, linear_key, tf_layers_keys = keys[0], keys[1], keys[2:]\n",
    "\n",
    "        self.tok_embeddings = eqx.nn.Embedding(args.vocab_size, args.dim, key=embed_key, dtype=dtype)\n",
    "        self.norm = RMSNorm(dim=args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "        self.output = eqx.nn.Linear(args.dim, args.vocab_size, use_bias=False, key=linear_key, dtype=dtype)\n",
    "        self.layers = [TransformerBlock(args, key=tf_layers_keys[i], dtype=dtype) for i in range(args.n_layers)] \n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_embeddings(self, x):\n",
    "        return jax.vmap(self.tok_embeddings)(x)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_mask(self, seqlen):\n",
    "        t = jnp.full((seqlen, seqlen), dtype=jnp.bfloat16, fill_value=1)\n",
    "        mask = jnp.tril(t, k=0)\n",
    "        # make the mask banded to account for sliding window\n",
    "        mask = jnp.triu(mask, k=-self.sliding_window)\n",
    "        mask = jnp.log(mask)\n",
    "        return mask\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_norm(self, x):\n",
    "        return jax.vmap(self.norm)(x)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def compute_output(self, x):\n",
    "        return jax.vmap(self.output)(x)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(1,))\n",
    "    def update_cache_values(self, idx, cache_k, cache_v, cache_k_updates, cache_v_updates):\n",
    "        cache_k = cache_k.at[idx, :, :, :].set(cache_k_updates)\n",
    "        cache_v = cache_v.at[idx, :, :, :].set(cache_v_updates)\n",
    "        return cache_k, cache_v\n",
    "\n",
    "    # def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "    #     # x is of shape (seqlen, )\n",
    "    #     h = self.compute_embeddings(x)\n",
    "\n",
    "    #     if x.shape[-1] > 1:\n",
    "    #         seqlen = x.shape[-1]\n",
    "    #         mask = self.compute_mask(seqlen)\n",
    "    #     else:\n",
    "    #         mask = None\n",
    "\n",
    "    #     # the for loop!!!\n",
    "\n",
    "    #     for i, layer in enumerate(self.layers):\n",
    "    #         #pdb.set_trace()\n",
    "    #         # h has shape (len(positions), dim)\n",
    "    #         # cache_ki has shape (sliding_window_len, head_dim, n_kv_heads)\n",
    "    #         h, cache_ki, cache_vi = layer(h, cos_freq, sin_freq, positions, mask, cache_k[i, ...], cache_v[i, ...]) # I think we could get away with creating blank entries for h, cache_ki, and cache_vi\n",
    "    #         # pdb.set_trace()\n",
    "    #         cache_k, cache_v = self.update_cache_values(i, cache_k, cache_v, cache_ki, cache_vi) # I think all this line is doing is plugging in cache_ki and cache_vi in the appropriate palce\n",
    "\n",
    "    #     h = self.compute_norm(h)\n",
    "    #     h = self.compute_output(h).astype(jnp.float32)\n",
    "    #     return h, cache_k, cache_v\n",
    "\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask):\n",
    "        \"\"\"\n",
    "        Edited to do prefilling instead of kv cache\n",
    "        \"\"\"\n",
    "        # x is of shape (seqlen, )\n",
    "        h = self.compute_embeddings(x)\n",
    "\n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        all_states = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # h has shape (len(positions), dim)\n",
    "            # cache_ki has shape (sliding_window_len, head_dim, n_kv_heads)\n",
    "            h = layer(h, cos_freq, sin_freq, positions, mask) # h has shape (T,D)\n",
    "            all_states.append(h)\n",
    "            # print(f\"at layer {i}, the shape of the feature is {h.shape}\")\n",
    "\n",
    "        # h = self.compute_norm(h)\n",
    "        # h = self.compute_output(h).astype(jnp.float32)\n",
    "        return jnp.array(all_states)\n",
    "\n",
    "    def partial_layers(self, layers, cos_freq, sin_freq, positions, mask):\n",
    "        \"\"\"\n",
    "        Ideally we could use jtu instead...\n",
    "        \"\"\"\n",
    "        def partial_layer(layer):\n",
    "            return partial(layer.__call__, cos_freq=cos_freq, sin_freq=sin_freq, positions=positions, mask=mask)\n",
    "\n",
    "        return [partial_layer(layer) for layer in layers] # really would prefer not to use list comprehension\n",
    "\n",
    "    def parallel_call(self, x, cos_freq, sin_freq, positions, mask, num_iters=7):\n",
    "        \"\"\"\n",
    "        Should give the same output as call, but using fixed point iterations\n",
    "        \"\"\"\n",
    "        h0 = self.compute_embeddings(x)\n",
    "        T, D = h0.shape\n",
    "\n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        # parallel logic\n",
    "        num_layers = len(self.layers)\n",
    "        # pdb.set_trace()\n",
    "        partialed_layers = self.partial_layers(self.layers, cos_freq, sin_freq, positions, mask)\n",
    "        states_guess = [\n",
    "            jnp.ones((T, D)) for _ in range(num_layers)\n",
    "        ]  # make sure to stay near rms norm equal to 1\n",
    "        # states_guess = [jnp.zeros((T, D)) for _ in range(num_layers)] # never do this when using rms norm, grads will explode\n",
    "        # calls out to deer\n",
    "        all_states = deer(h0, partialed_layers, states_guess, num_iters) # (batch_size, num_iters, num_layers, T, D)\n",
    "\n",
    "        return jnp.array(all_states)\n",
    "        # h = all_states[-1][-1]\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        # h = self.compute_norm(h)\n",
    "        # h = self.compute_output(h).astype(jnp.float32)\n",
    "        # return h\n",
    "\n",
    "\n",
    "def deer(x, layers, states_guess, num_iters, k =1):\n",
    "    \"\"\"\n",
    "    runs deer (fiddly logic in the rearrange)\n",
    "\n",
    "    Args:\n",
    "      x: (T, d) initial inputs to transformer stack\n",
    "      layers: list of TransformerLayer objects (the functions that propagate information over the stack)\n",
    "      states_guess: list of length num_layers of (T, D) shaped arrays; this is the initial guess for the states. don't make them all zero!\n",
    "      num_iters: number of iterations to run for\n",
    "      k: damping factor\n",
    "    \"\"\"\n",
    "    T, D = x.shape\n",
    "    num_layers = len(layers)\n",
    "\n",
    "    @jax.vmap\n",
    "    def binary_op(q_i, q_j):\n",
    "        \"\"\"Binary operator for parallel scan of linear recurrence. Assumes a full Jacobian matrix A\n",
    "        Args:\n",
    "            q_i: tuple containing J_i and b_i at position i       (P,P), (P,)\n",
    "            q_j: tuple containing J_j and b_j at position j       (P,P), (P,)\n",
    "        Returns:\n",
    "            new element ( A_out, Bu_out )\n",
    "        \"\"\"\n",
    "        A_i, b_i = q_i\n",
    "        A_j, b_j = q_j\n",
    "        return A_j @ A_i, A_j @ b_i + b_j\n",
    "\n",
    "    def step(states, args):\n",
    "        \"\"\"\n",
    "        This step is a single deer iteration (will eventually be sequential scanned)\n",
    "        Args:\n",
    "          states: list of length num_layers of (T, D) shaped arrays\n",
    "          args: None\n",
    "        \"\"\"\n",
    "        states = [x] + states[:-1]  # length num_layers\n",
    "        print(f\"states shape is {states[0].shape}\")\n",
    "        fs = jnp.array(\n",
    "            jtu.tree_map(lambda x, f: f(x), states, layers)\n",
    "        )  # (num_layers, T,D) arrays, note that we keep states as a list so we can use jtu.tree_map\n",
    "        print(f\"fs shape is {fs.shape}\")\n",
    "        As = jnp.array(\n",
    "            jtu.tree_map(lambda x, f: jax.jacrev(f)(x), states, layers) # this line seems to be the bottleneck, but that's odd bc we'd expect someone to take this grads during backprop\n",
    "        )  # (num_layers, T, D, T, D) tensors\n",
    "        print(f\"As shape is {As.shape}\")\n",
    "        As = As.at[0].set(jnp.zeros((T, D, T, D)))\n",
    "        # pdb.set_trace()\n",
    "        # need to make the first A equal to zero\n",
    "        states = jnp.array(states)  # (num_layers, T,D)\n",
    "        # do some rearranging\n",
    "        print(\"starting the rearranges\")\n",
    "        flattened_states = jnp.reshape(states, (num_layers, T * D))  # (num_layers, T*D)\n",
    "        flattened_As = jnp.reshape(\n",
    "            As, (num_layers, T * D, T * D)\n",
    "        )  # (num_layers, T*D, T*D)\n",
    "        # somehow, we aren't even getting here\n",
    "        # print(\"we are about to start computing eigenvalues\")\n",
    "        # for A in flattened_As:\n",
    "        #     print(jnp.linalg.eigvals(A))\n",
    "        # pdb.set_trace()\n",
    "        flattened_fs = jnp.reshape(fs, (num_layers, T * D))  # (num_layers, T*D)\n",
    "        bs = flattened_fs - jnp.einsum(\n",
    "            \"tij,tj->ti\", flattened_As, flattened_states\n",
    "        )  # (num_layers, T*D)\n",
    "\n",
    "        # finally ready to evaluate linearized dynamics (in parallel)\n",
    "        print(\"we are about to start the associative scan\")\n",
    "        _, new_states = jax.lax.associative_scan(\n",
    "            binary_op, (flattened_As, bs)\n",
    "        )  # parallel operation\n",
    "        # new_states = jnp.nan_to_num(new_states)  # zero out nans, (num_layers, T*D)\n",
    "        new_states = jnp.reshape(new_states, (num_layers, T, D))  # (num_layers, T, D)\n",
    "        return list(new_states), new_states\n",
    "\n",
    "    print(\"starting deer outer loop\")\n",
    "    # states_guess, iter_hist = jax.lax.scan(\n",
    "    #     step, states_guess, None, length=num_iters\n",
    "    # )  # state_iters will show all the intermediate traces\n",
    "\n",
    "    iter_hist = []\n",
    "    for i in range(num_iters):\n",
    "        print()\n",
    "        print(\"-----------------\")\n",
    "        print(f\"iteration {i}\")\n",
    "        print(\"-----------------\")\n",
    "        print()\n",
    "        states_guess, iter_hist_add = step(states_guess, None)\n",
    "        iter_hist.append(iter_hist_add)\n",
    "\n",
    "    # return states_guess\n",
    "    return jnp.array(iter_hist) # (num_iters, num_layers, T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5a7c63f-4be6-4bad-b6f5-b77c77bcc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArgs(NamedTuple):\n",
    "    dim: int\n",
    "    n_layers: int\n",
    "    n_heads: int\n",
    "    n_kv_heads: int\n",
    "    head_dim: int\n",
    "    hidden_dim: int\n",
    "    vocab_size: int\n",
    "    sliding_window: int\n",
    "    norm_eps: float\n",
    "    max_batch_size: int = 1\n",
    "\n",
    "# maybe we could do a proto_params.json, and just not load in the weights\n",
    "with open(\n",
    "    \"/Users/xaviergonzalez/Desktop/xavier_folders/stanford/cs229s/mistral_jax/model_files/params.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    #with open('./mistral-7B-v0.1/params.json', 'r') as f:\n",
    "    args = ModelArgs(**json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a2d2cf-40f6-48af-a70f-37847532e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_weights_from_torch(torch_weights, eqx_model):\n",
    "    def load_weights(path, leaf):\n",
    "        path_pieces = []\n",
    "        for path_elem in path:\n",
    "            if isinstance(path_elem, jax.tree_util.GetAttrKey):\n",
    "                 path_pieces.append(path_elem.name)\n",
    "            elif isinstance(path_elem, jax.tree_util.SequenceKey):\n",
    "                 path_pieces.append(str(path_elem.idx))\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported path type {type(path_elem)}\")\n",
    "\n",
    "        path_pieces = \".\".join(path_pieces)\n",
    "        \n",
    "        if \"weight\" in path_pieces:\n",
    "            weight = torch_weights[path_pieces]\n",
    "            weight = jnp.asarray(weight.float().numpy(), dtype=jnp.bfloat16)\n",
    "            assert weight.shape == leaf.shape\n",
    "            assert weight.dtype == leaf.dtype\n",
    "            return weight\n",
    "        else:\n",
    "            print(f\"Weights not ported for: {path_pieces}\")\n",
    "            return leaf\n",
    "\n",
    "    return jax.tree_util.tree_map_with_path(load_weights, eqx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67530c78-98a9-4f84-aa4b-af0819b5f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights not ported for: layers.0.dim\n",
      "Weights not ported for: layers.0.n_heads\n",
      "Weights not ported for: layers.0.attention.dim\n",
      "Weights not ported for: layers.0.attention.n_heads\n",
      "Weights not ported for: layers.0.attention.head_dim\n",
      "Weights not ported for: layers.0.attention.n_kv_heads\n",
      "Weights not ported for: layers.0.attention.kv_repeats\n",
      "Weights not ported for: layers.0.attention.sliding_window\n",
      "Weights not ported for: layers.0.attention.scale\n",
      "Weights not ported for: layers.0.attention_norm.eps\n",
      "Weights not ported for: layers.0.ffn_norm.eps\n",
      "Weights not ported for: layers.1.dim\n",
      "Weights not ported for: layers.1.n_heads\n",
      "Weights not ported for: layers.1.attention.dim\n",
      "Weights not ported for: layers.1.attention.n_heads\n",
      "Weights not ported for: layers.1.attention.head_dim\n",
      "Weights not ported for: layers.1.attention.n_kv_heads\n",
      "Weights not ported for: layers.1.attention.kv_repeats\n",
      "Weights not ported for: layers.1.attention.sliding_window\n",
      "Weights not ported for: layers.1.attention.scale\n",
      "Weights not ported for: layers.1.attention_norm.eps\n",
      "Weights not ported for: layers.1.ffn_norm.eps\n",
      "Weights not ported for: layers.2.dim\n",
      "Weights not ported for: layers.2.n_heads\n",
      "Weights not ported for: layers.2.attention.dim\n",
      "Weights not ported for: layers.2.attention.n_heads\n",
      "Weights not ported for: layers.2.attention.head_dim\n",
      "Weights not ported for: layers.2.attention.n_kv_heads\n",
      "Weights not ported for: layers.2.attention.kv_repeats\n",
      "Weights not ported for: layers.2.attention.sliding_window\n",
      "Weights not ported for: layers.2.attention.scale\n",
      "Weights not ported for: layers.2.attention_norm.eps\n",
      "Weights not ported for: layers.2.ffn_norm.eps\n",
      "Weights not ported for: layers.3.dim\n",
      "Weights not ported for: layers.3.n_heads\n",
      "Weights not ported for: layers.3.attention.dim\n",
      "Weights not ported for: layers.3.attention.n_heads\n",
      "Weights not ported for: layers.3.attention.head_dim\n",
      "Weights not ported for: layers.3.attention.n_kv_heads\n",
      "Weights not ported for: layers.3.attention.kv_repeats\n",
      "Weights not ported for: layers.3.attention.sliding_window\n",
      "Weights not ported for: layers.3.attention.scale\n",
      "Weights not ported for: layers.3.attention_norm.eps\n",
      "Weights not ported for: layers.3.ffn_norm.eps\n",
      "Weights not ported for: layers.4.dim\n",
      "Weights not ported for: layers.4.n_heads\n",
      "Weights not ported for: layers.4.attention.dim\n",
      "Weights not ported for: layers.4.attention.n_heads\n",
      "Weights not ported for: layers.4.attention.head_dim\n",
      "Weights not ported for: layers.4.attention.n_kv_heads\n",
      "Weights not ported for: layers.4.attention.kv_repeats\n",
      "Weights not ported for: layers.4.attention.sliding_window\n",
      "Weights not ported for: layers.4.attention.scale\n",
      "Weights not ported for: layers.4.attention_norm.eps\n",
      "Weights not ported for: layers.4.ffn_norm.eps\n",
      "Weights not ported for: layers.5.dim\n",
      "Weights not ported for: layers.5.n_heads\n",
      "Weights not ported for: layers.5.attention.dim\n",
      "Weights not ported for: layers.5.attention.n_heads\n",
      "Weights not ported for: layers.5.attention.head_dim\n",
      "Weights not ported for: layers.5.attention.n_kv_heads\n",
      "Weights not ported for: layers.5.attention.kv_repeats\n",
      "Weights not ported for: layers.5.attention.sliding_window\n",
      "Weights not ported for: layers.5.attention.scale\n",
      "Weights not ported for: layers.5.attention_norm.eps\n",
      "Weights not ported for: layers.5.ffn_norm.eps\n",
      "Weights not ported for: layers.6.dim\n",
      "Weights not ported for: layers.6.n_heads\n",
      "Weights not ported for: layers.6.attention.dim\n",
      "Weights not ported for: layers.6.attention.n_heads\n",
      "Weights not ported for: layers.6.attention.head_dim\n",
      "Weights not ported for: layers.6.attention.n_kv_heads\n",
      "Weights not ported for: layers.6.attention.kv_repeats\n",
      "Weights not ported for: layers.6.attention.sliding_window\n",
      "Weights not ported for: layers.6.attention.scale\n",
      "Weights not ported for: layers.6.attention_norm.eps\n",
      "Weights not ported for: layers.6.ffn_norm.eps\n",
      "Weights not ported for: layers.7.dim\n",
      "Weights not ported for: layers.7.n_heads\n",
      "Weights not ported for: layers.7.attention.dim\n",
      "Weights not ported for: layers.7.attention.n_heads\n",
      "Weights not ported for: layers.7.attention.head_dim\n",
      "Weights not ported for: layers.7.attention.n_kv_heads\n",
      "Weights not ported for: layers.7.attention.kv_repeats\n",
      "Weights not ported for: layers.7.attention.sliding_window\n",
      "Weights not ported for: layers.7.attention.scale\n",
      "Weights not ported for: layers.7.attention_norm.eps\n",
      "Weights not ported for: layers.7.ffn_norm.eps\n",
      "Weights not ported for: layers.8.dim\n",
      "Weights not ported for: layers.8.n_heads\n",
      "Weights not ported for: layers.8.attention.dim\n",
      "Weights not ported for: layers.8.attention.n_heads\n",
      "Weights not ported for: layers.8.attention.head_dim\n",
      "Weights not ported for: layers.8.attention.n_kv_heads\n",
      "Weights not ported for: layers.8.attention.kv_repeats\n",
      "Weights not ported for: layers.8.attention.sliding_window\n",
      "Weights not ported for: layers.8.attention.scale\n",
      "Weights not ported for: layers.8.attention_norm.eps\n",
      "Weights not ported for: layers.8.ffn_norm.eps\n",
      "Weights not ported for: layers.9.dim\n",
      "Weights not ported for: layers.9.n_heads\n",
      "Weights not ported for: layers.9.attention.dim\n",
      "Weights not ported for: layers.9.attention.n_heads\n",
      "Weights not ported for: layers.9.attention.head_dim\n",
      "Weights not ported for: layers.9.attention.n_kv_heads\n",
      "Weights not ported for: layers.9.attention.kv_repeats\n",
      "Weights not ported for: layers.9.attention.sliding_window\n",
      "Weights not ported for: layers.9.attention.scale\n",
      "Weights not ported for: layers.9.attention_norm.eps\n",
      "Weights not ported for: layers.9.ffn_norm.eps\n",
      "Weights not ported for: layers.10.dim\n",
      "Weights not ported for: layers.10.n_heads\n",
      "Weights not ported for: layers.10.attention.dim\n",
      "Weights not ported for: layers.10.attention.n_heads\n",
      "Weights not ported for: layers.10.attention.head_dim\n",
      "Weights not ported for: layers.10.attention.n_kv_heads\n",
      "Weights not ported for: layers.10.attention.kv_repeats\n",
      "Weights not ported for: layers.10.attention.sliding_window\n",
      "Weights not ported for: layers.10.attention.scale\n",
      "Weights not ported for: layers.10.attention_norm.eps\n",
      "Weights not ported for: layers.10.ffn_norm.eps\n",
      "Weights not ported for: layers.11.dim\n",
      "Weights not ported for: layers.11.n_heads\n",
      "Weights not ported for: layers.11.attention.dim\n",
      "Weights not ported for: layers.11.attention.n_heads\n",
      "Weights not ported for: layers.11.attention.head_dim\n",
      "Weights not ported for: layers.11.attention.n_kv_heads\n",
      "Weights not ported for: layers.11.attention.kv_repeats\n",
      "Weights not ported for: layers.11.attention.sliding_window\n",
      "Weights not ported for: layers.11.attention.scale\n",
      "Weights not ported for: layers.11.attention_norm.eps\n",
      "Weights not ported for: layers.11.ffn_norm.eps\n",
      "Weights not ported for: layers.12.dim\n",
      "Weights not ported for: layers.12.n_heads\n",
      "Weights not ported for: layers.12.attention.dim\n",
      "Weights not ported for: layers.12.attention.n_heads\n",
      "Weights not ported for: layers.12.attention.head_dim\n",
      "Weights not ported for: layers.12.attention.n_kv_heads\n",
      "Weights not ported for: layers.12.attention.kv_repeats\n",
      "Weights not ported for: layers.12.attention.sliding_window\n",
      "Weights not ported for: layers.12.attention.scale\n",
      "Weights not ported for: layers.12.attention_norm.eps\n",
      "Weights not ported for: layers.12.ffn_norm.eps\n",
      "Weights not ported for: layers.13.dim\n",
      "Weights not ported for: layers.13.n_heads\n",
      "Weights not ported for: layers.13.attention.dim\n",
      "Weights not ported for: layers.13.attention.n_heads\n",
      "Weights not ported for: layers.13.attention.head_dim\n",
      "Weights not ported for: layers.13.attention.n_kv_heads\n",
      "Weights not ported for: layers.13.attention.kv_repeats\n",
      "Weights not ported for: layers.13.attention.sliding_window\n",
      "Weights not ported for: layers.13.attention.scale\n",
      "Weights not ported for: layers.13.attention_norm.eps\n",
      "Weights not ported for: layers.13.ffn_norm.eps\n",
      "Weights not ported for: layers.14.dim\n",
      "Weights not ported for: layers.14.n_heads\n",
      "Weights not ported for: layers.14.attention.dim\n",
      "Weights not ported for: layers.14.attention.n_heads\n",
      "Weights not ported for: layers.14.attention.head_dim\n",
      "Weights not ported for: layers.14.attention.n_kv_heads\n",
      "Weights not ported for: layers.14.attention.kv_repeats\n",
      "Weights not ported for: layers.14.attention.sliding_window\n",
      "Weights not ported for: layers.14.attention.scale\n",
      "Weights not ported for: layers.14.attention_norm.eps\n",
      "Weights not ported for: layers.14.ffn_norm.eps\n",
      "Weights not ported for: layers.15.dim\n",
      "Weights not ported for: layers.15.n_heads\n",
      "Weights not ported for: layers.15.attention.dim\n",
      "Weights not ported for: layers.15.attention.n_heads\n",
      "Weights not ported for: layers.15.attention.head_dim\n",
      "Weights not ported for: layers.15.attention.n_kv_heads\n",
      "Weights not ported for: layers.15.attention.kv_repeats\n",
      "Weights not ported for: layers.15.attention.sliding_window\n",
      "Weights not ported for: layers.15.attention.scale\n",
      "Weights not ported for: layers.15.attention_norm.eps\n",
      "Weights not ported for: layers.15.ffn_norm.eps\n",
      "Weights not ported for: layers.16.dim\n",
      "Weights not ported for: layers.16.n_heads\n",
      "Weights not ported for: layers.16.attention.dim\n",
      "Weights not ported for: layers.16.attention.n_heads\n",
      "Weights not ported for: layers.16.attention.head_dim\n",
      "Weights not ported for: layers.16.attention.n_kv_heads\n",
      "Weights not ported for: layers.16.attention.kv_repeats\n",
      "Weights not ported for: layers.16.attention.sliding_window\n",
      "Weights not ported for: layers.16.attention.scale\n",
      "Weights not ported for: layers.16.attention_norm.eps\n",
      "Weights not ported for: layers.16.ffn_norm.eps\n",
      "Weights not ported for: layers.17.dim\n",
      "Weights not ported for: layers.17.n_heads\n",
      "Weights not ported for: layers.17.attention.dim\n",
      "Weights not ported for: layers.17.attention.n_heads\n",
      "Weights not ported for: layers.17.attention.head_dim\n",
      "Weights not ported for: layers.17.attention.n_kv_heads\n",
      "Weights not ported for: layers.17.attention.kv_repeats\n",
      "Weights not ported for: layers.17.attention.sliding_window\n",
      "Weights not ported for: layers.17.attention.scale\n",
      "Weights not ported for: layers.17.attention_norm.eps\n",
      "Weights not ported for: layers.17.ffn_norm.eps\n",
      "Weights not ported for: layers.18.dim\n",
      "Weights not ported for: layers.18.n_heads\n",
      "Weights not ported for: layers.18.attention.dim\n",
      "Weights not ported for: layers.18.attention.n_heads\n",
      "Weights not ported for: layers.18.attention.head_dim\n",
      "Weights not ported for: layers.18.attention.n_kv_heads\n",
      "Weights not ported for: layers.18.attention.kv_repeats\n",
      "Weights not ported for: layers.18.attention.sliding_window\n",
      "Weights not ported for: layers.18.attention.scale\n",
      "Weights not ported for: layers.18.attention_norm.eps\n",
      "Weights not ported for: layers.18.ffn_norm.eps\n",
      "Weights not ported for: layers.19.dim\n",
      "Weights not ported for: layers.19.n_heads\n",
      "Weights not ported for: layers.19.attention.dim\n",
      "Weights not ported for: layers.19.attention.n_heads\n",
      "Weights not ported for: layers.19.attention.head_dim\n",
      "Weights not ported for: layers.19.attention.n_kv_heads\n",
      "Weights not ported for: layers.19.attention.kv_repeats\n",
      "Weights not ported for: layers.19.attention.sliding_window\n",
      "Weights not ported for: layers.19.attention.scale\n",
      "Weights not ported for: layers.19.attention_norm.eps\n",
      "Weights not ported for: layers.19.ffn_norm.eps\n",
      "Weights not ported for: layers.20.dim\n",
      "Weights not ported for: layers.20.n_heads\n",
      "Weights not ported for: layers.20.attention.dim\n",
      "Weights not ported for: layers.20.attention.n_heads\n",
      "Weights not ported for: layers.20.attention.head_dim\n",
      "Weights not ported for: layers.20.attention.n_kv_heads\n",
      "Weights not ported for: layers.20.attention.kv_repeats\n",
      "Weights not ported for: layers.20.attention.sliding_window\n",
      "Weights not ported for: layers.20.attention.scale\n",
      "Weights not ported for: layers.20.attention_norm.eps\n",
      "Weights not ported for: layers.20.ffn_norm.eps\n",
      "Weights not ported for: layers.21.dim\n",
      "Weights not ported for: layers.21.n_heads\n",
      "Weights not ported for: layers.21.attention.dim\n",
      "Weights not ported for: layers.21.attention.n_heads\n",
      "Weights not ported for: layers.21.attention.head_dim\n",
      "Weights not ported for: layers.21.attention.n_kv_heads\n",
      "Weights not ported for: layers.21.attention.kv_repeats\n",
      "Weights not ported for: layers.21.attention.sliding_window\n",
      "Weights not ported for: layers.21.attention.scale\n",
      "Weights not ported for: layers.21.attention_norm.eps\n",
      "Weights not ported for: layers.21.ffn_norm.eps\n",
      "Weights not ported for: layers.22.dim\n",
      "Weights not ported for: layers.22.n_heads\n",
      "Weights not ported for: layers.22.attention.dim\n",
      "Weights not ported for: layers.22.attention.n_heads\n",
      "Weights not ported for: layers.22.attention.head_dim\n",
      "Weights not ported for: layers.22.attention.n_kv_heads\n",
      "Weights not ported for: layers.22.attention.kv_repeats\n",
      "Weights not ported for: layers.22.attention.sliding_window\n",
      "Weights not ported for: layers.22.attention.scale\n",
      "Weights not ported for: layers.22.attention_norm.eps\n",
      "Weights not ported for: layers.22.ffn_norm.eps\n",
      "Weights not ported for: layers.23.dim\n",
      "Weights not ported for: layers.23.n_heads\n",
      "Weights not ported for: layers.23.attention.dim\n",
      "Weights not ported for: layers.23.attention.n_heads\n",
      "Weights not ported for: layers.23.attention.head_dim\n",
      "Weights not ported for: layers.23.attention.n_kv_heads\n",
      "Weights not ported for: layers.23.attention.kv_repeats\n",
      "Weights not ported for: layers.23.attention.sliding_window\n",
      "Weights not ported for: layers.23.attention.scale\n",
      "Weights not ported for: layers.23.attention_norm.eps\n",
      "Weights not ported for: layers.23.ffn_norm.eps\n",
      "Weights not ported for: layers.24.dim\n",
      "Weights not ported for: layers.24.n_heads\n",
      "Weights not ported for: layers.24.attention.dim\n",
      "Weights not ported for: layers.24.attention.n_heads\n",
      "Weights not ported for: layers.24.attention.head_dim\n",
      "Weights not ported for: layers.24.attention.n_kv_heads\n",
      "Weights not ported for: layers.24.attention.kv_repeats\n",
      "Weights not ported for: layers.24.attention.sliding_window\n",
      "Weights not ported for: layers.24.attention.scale\n",
      "Weights not ported for: layers.24.attention_norm.eps\n",
      "Weights not ported for: layers.24.ffn_norm.eps\n",
      "Weights not ported for: layers.25.dim\n",
      "Weights not ported for: layers.25.n_heads\n",
      "Weights not ported for: layers.25.attention.dim\n",
      "Weights not ported for: layers.25.attention.n_heads\n",
      "Weights not ported for: layers.25.attention.head_dim\n",
      "Weights not ported for: layers.25.attention.n_kv_heads\n",
      "Weights not ported for: layers.25.attention.kv_repeats\n",
      "Weights not ported for: layers.25.attention.sliding_window\n",
      "Weights not ported for: layers.25.attention.scale\n",
      "Weights not ported for: layers.25.attention_norm.eps\n",
      "Weights not ported for: layers.25.ffn_norm.eps\n",
      "Weights not ported for: layers.26.dim\n",
      "Weights not ported for: layers.26.n_heads\n",
      "Weights not ported for: layers.26.attention.dim\n",
      "Weights not ported for: layers.26.attention.n_heads\n",
      "Weights not ported for: layers.26.attention.head_dim\n",
      "Weights not ported for: layers.26.attention.n_kv_heads\n",
      "Weights not ported for: layers.26.attention.kv_repeats\n",
      "Weights not ported for: layers.26.attention.sliding_window\n",
      "Weights not ported for: layers.26.attention.scale\n",
      "Weights not ported for: layers.26.attention_norm.eps\n",
      "Weights not ported for: layers.26.ffn_norm.eps\n",
      "Weights not ported for: layers.27.dim\n",
      "Weights not ported for: layers.27.n_heads\n",
      "Weights not ported for: layers.27.attention.dim\n",
      "Weights not ported for: layers.27.attention.n_heads\n",
      "Weights not ported for: layers.27.attention.head_dim\n",
      "Weights not ported for: layers.27.attention.n_kv_heads\n",
      "Weights not ported for: layers.27.attention.kv_repeats\n",
      "Weights not ported for: layers.27.attention.sliding_window\n",
      "Weights not ported for: layers.27.attention.scale\n",
      "Weights not ported for: layers.27.attention_norm.eps\n",
      "Weights not ported for: layers.27.ffn_norm.eps\n",
      "Weights not ported for: layers.28.dim\n",
      "Weights not ported for: layers.28.n_heads\n",
      "Weights not ported for: layers.28.attention.dim\n",
      "Weights not ported for: layers.28.attention.n_heads\n",
      "Weights not ported for: layers.28.attention.head_dim\n",
      "Weights not ported for: layers.28.attention.n_kv_heads\n",
      "Weights not ported for: layers.28.attention.kv_repeats\n",
      "Weights not ported for: layers.28.attention.sliding_window\n",
      "Weights not ported for: layers.28.attention.scale\n",
      "Weights not ported for: layers.28.attention_norm.eps\n",
      "Weights not ported for: layers.28.ffn_norm.eps\n",
      "Weights not ported for: layers.29.dim\n",
      "Weights not ported for: layers.29.n_heads\n",
      "Weights not ported for: layers.29.attention.dim\n",
      "Weights not ported for: layers.29.attention.n_heads\n",
      "Weights not ported for: layers.29.attention.head_dim\n",
      "Weights not ported for: layers.29.attention.n_kv_heads\n",
      "Weights not ported for: layers.29.attention.kv_repeats\n",
      "Weights not ported for: layers.29.attention.sliding_window\n",
      "Weights not ported for: layers.29.attention.scale\n",
      "Weights not ported for: layers.29.attention_norm.eps\n",
      "Weights not ported for: layers.29.ffn_norm.eps\n",
      "Weights not ported for: layers.30.dim\n",
      "Weights not ported for: layers.30.n_heads\n",
      "Weights not ported for: layers.30.attention.dim\n",
      "Weights not ported for: layers.30.attention.n_heads\n",
      "Weights not ported for: layers.30.attention.head_dim\n",
      "Weights not ported for: layers.30.attention.n_kv_heads\n",
      "Weights not ported for: layers.30.attention.kv_repeats\n",
      "Weights not ported for: layers.30.attention.sliding_window\n",
      "Weights not ported for: layers.30.attention.scale\n",
      "Weights not ported for: layers.30.attention_norm.eps\n",
      "Weights not ported for: layers.30.ffn_norm.eps\n",
      "Weights not ported for: layers.31.dim\n",
      "Weights not ported for: layers.31.n_heads\n",
      "Weights not ported for: layers.31.attention.dim\n",
      "Weights not ported for: layers.31.attention.n_heads\n",
      "Weights not ported for: layers.31.attention.head_dim\n",
      "Weights not ported for: layers.31.attention.n_kv_heads\n",
      "Weights not ported for: layers.31.attention.kv_repeats\n",
      "Weights not ported for: layers.31.attention.sliding_window\n",
      "Weights not ported for: layers.31.attention.scale\n",
      "Weights not ported for: layers.31.attention_norm.eps\n",
      "Weights not ported for: layers.31.ffn_norm.eps\n",
      "Weights not ported for: norm.eps\n",
      "Weights not ported for: vocab_size\n",
      "Weights not ported for: n_layers\n",
      "Weights not ported for: sliding_window\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16) # sets architecutre\n",
    "model = port_weights_from_torch(state_dict, model) # fills with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7da969f6-eb91-4df5-9976-1db480914a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_k = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "# cache_v = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "NUM_ITERS = 4\n",
    "cos_freq, sin_freq = precompute_frequencies(args.head_dim, 128000)\n",
    "vmapped = jax.vmap(partial(model.parallel_call, num_iters=NUM_ITERS), in_axes=(0, None, None, None, None)) # vmapped is the name of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_seq = jax.vmap(\n",
    "    model,\n",
    "    in_axes=(0, None, None, None, None),\n",
    ")  # vmapped is the name of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "001d96e5-f58d-4ea4-b878-92abcfcb85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting deer outer loop\n",
      "\n",
      "-----------------\n",
      "iteration 0\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 1\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 2\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n",
      "\n",
      "-----------------\n",
      "iteration 3\n",
      "-----------------\n",
      "\n",
      "states shape is (1, 4096)\n",
      "fs shape is (32, 1, 4096)\n",
      "As shape is (32, 1, 4096, 1, 4096)\n",
      "starting the rearranges\n",
      "we are about to start the associative scan\n"
     ]
    }
   ],
   "source": [
    "fake_pos = jnp.array([0], dtype=jnp.int32)\n",
    "fake_inp = jnp.asarray([[1]], dtype=jnp.int32)\n",
    "fake_mask = None\n",
    "\n",
    "hist_seq = vmap_seq(\n",
    "    fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask\n",
    ")\n",
    "hist_parr = vmapped(fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask)\n",
    "jnp.save(f\"parallel_history_NumIters_{NUM_ITERS}.npy\", hist_parr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 1, 4096)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.load(\"logits.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 32, 1, 4096)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 1, 4096)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n"
     ]
    }
   ],
   "source": [
    "errors_per_iter_and_layer = jnp.mean(jnp.abs((hist_parr[0] - hist_seq).squeeze()), axis=-1)\n",
    "print(jnp.shape(errors_per_iter_and_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.0000000e+00, 1.9379653e-01, 1.9577831e-01, 1.9842212e-01,\n",
       "        2.0143938e-01, 2.0685999e-01, 2.1126443e-01, 2.1645682e-01,\n",
       "        2.2188202e-01, 2.2748125e-01, 2.3476216e-01, 2.4526620e-01,\n",
       "        2.5457206e-01, 2.6582250e-01, 2.8100759e-01, 2.9988283e-01,\n",
       "        3.1659949e-01, 3.3331496e-01, 3.5449558e-01, 3.7569577e-01,\n",
       "        3.9936203e-01, 4.2514843e-01, 4.4629109e-01, 4.7540399e-01,\n",
       "        5.1046073e-01, 5.4050022e-01, 5.7685274e-01, 6.0469234e-01,\n",
       "        6.3749349e-01, 7.1767086e-01, 8.5089880e-01, 2.8431191e+00],\n",
       "       [0.0000000e+00, 5.0305593e-04, 6.0457230e-02, 1.3351017e-01,\n",
       "        2.5135112e-01, 4.1541496e-01, 6.3431966e-01, 9.3786740e-01,\n",
       "        1.2459170e+00, 1.5389332e+00, 1.8103627e+00, 2.0912023e+00,\n",
       "        2.3293934e+00, 2.5727761e+00, 2.8292270e+00, 3.0645685e+00,\n",
       "        3.3717854e+00, 3.6113937e+00, 3.8956900e+00, 4.2682900e+00,\n",
       "        4.6444583e+00, 5.0535717e+00, 5.3322926e+00, 5.7752161e+00,\n",
       "        6.2550097e+00, 6.7042480e+00, 7.0214586e+00, 7.4044428e+00,\n",
       "        7.8834724e+00, 8.4252472e+00, 8.7276516e+00, 8.9039898e+00]],      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_per_iter_and_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x6a02c6f60>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(errors_per_iter_and_layer, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[[-8.92639160e-04,  2.65502930e-03, -1.84570312e-01, ...,\n",
       "            7.62939453e-06, -1.43432617e-03, -1.95312500e-03]],\n",
       "\n",
       "         [[-8.91094469e-03, -6.18494023e-03, -1.85622007e-01, ...,\n",
       "            9.09190509e-04, -5.82782552e-03, -1.42973997e-02]],\n",
       "\n",
       "         [[-6.07582554e-03, -3.72581817e-02, -1.96056485e-01, ...,\n",
       "           -2.17162538e-02, -3.14874249e-03, -9.00264457e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.10669410e+00,  1.49299145e-01, -5.95834732e-01, ...,\n",
       "            3.55023921e-01,  1.29173613e+00, -5.56365788e-01]],\n",
       "\n",
       "         [[ 1.05325460e+00,  1.63162947e-02, -5.39088607e-01, ...,\n",
       "            5.94611347e-01,  1.15215635e+00, -6.52567387e-01]],\n",
       "\n",
       "         [[ 4.23761547e-01,  2.28124112e-01, -1.06671560e+00, ...,\n",
       "            5.91840267e-01,  8.96652579e-01, -7.07928896e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.92639160e-04,  2.65502930e-03, -1.84570312e-01, ...,\n",
       "            7.62939453e-06, -1.43432617e-03, -1.95312500e-03]],\n",
       "\n",
       "         [[-1.20094955e-01, -3.91652256e-01, -1.39715612e-01, ...,\n",
       "            7.06485100e-03,  2.07763314e-02, -5.91178797e-02]],\n",
       "\n",
       "         [[-1.16284236e-01, -4.00582671e-01, -2.51705170e-01, ...,\n",
       "            2.94541754e-02,  1.13582872e-02, -9.83709916e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.72007227e+00,  1.60713234e+01, -9.77484894e+00, ...,\n",
       "           -4.83511925e+00,  2.95893650e+01, -2.57335949e+00]],\n",
       "\n",
       "         [[ 9.25865936e+00,  1.67624340e+01, -5.88470030e+00, ...,\n",
       "            4.59273815e-01,  3.09054546e+01, -3.87069154e+00]],\n",
       "\n",
       "         [[ 1.20738783e+01,  1.76835766e+01, -8.13421631e+00, ...,\n",
       "            2.23497677e+00,  3.07850189e+01, -5.26595545e+00]]]]],      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75b07b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp_flat = jnp.asarray([1, 832, 349, 265, 1369], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a00741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-5.84375   , -5.8125    , -0.09960938, ..., -4.3125    ,\n",
       "        -3.515625  , -4.03125   ],\n",
       "       [-8.875     , -8.8125    ,  0.39257812, ..., -6.4375    ,\n",
       "        -6.6875    , -7.15625   ],\n",
       "       [-7.09375   , -6.875     , -0.8359375 , ..., -6.96875   ,\n",
       "        -5.4375    , -4.59375   ],\n",
       "       [-7.03125   , -7.03125   ,  0.75      , ..., -5.75      ,\n",
       "        -7.625     , -5.75      ],\n",
       "       [-7.46875   , -7.53125   ,  0.73828125, ..., -7.1875    ,\n",
       "        -7.65625   , -5.75      ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(fake_inp_flat, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos, fake_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.RMSNorm"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.0936636, dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sqrt(jnp.mean(logits[0, -1, 0] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a3b4f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(5.442458, dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sqrt(jnp.mean(model.norm(logits[0, -1, 0]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7b45669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp_flat = jnp.asarray([1, 832, 349, 265, 1369], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d2ae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ffc5c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89ac0483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_embeddings(fake_inp_flat).shape # (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1f2421f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc248cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.compute_embeddings(fake_inp_flat)\n",
    "xq, xk, xv = attn.compute_qkv(x)\n",
    "key, value = attn.prefill(xk, xv)\n",
    "output = attn.compute_scores_and_output(xq, key, value, fake_mask, x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406da556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e23a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4096)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a4e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a71fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape # (T, n_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4f380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xk.shape # (T, n_kv_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.shape # (T, n_kv_heads, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.compute_scores_and_output(xq, xk, xv, fake_mask, 5).shape # (T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5374a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_inp_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 96\u001b[0m, in \u001b[0;36mAttention.__call__\u001b[0;34m(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\u001b[0m\n\u001b[1;32m     93\u001b[0m xk \u001b[38;5;241m=\u001b[39m calculate_rope(xk, cos_freq, sin_freq, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# 3. Update cache\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m cache_k, cache_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_cache_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 4. Generation\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m positions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# prefill\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mAttention.update_cache_values\u001b[0;34m(self, xk, xv, cache_k, cache_v, positions)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_cache_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, xk, xv, cache_k, cache_v, positions):\n\u001b[0;32m---> 53\u001b[0m     cache_k \u001b[38;5;241m=\u001b[39m \u001b[43mcache_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mset(xk[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     54\u001b[0m     cache_v \u001b[38;5;241m=\u001b[39m cache_v\u001b[38;5;241m.\u001b[39mat[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mset(xv[positions, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache_k, cache_v\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'at'"
     ]
    }
   ],
   "source": [
    "attn(model.compute_embeddings(fake_inp_flat), cos_freq[:5], sin_freq[:5], fake_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3410598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc44e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(model.compute_embeddings)(fake_inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 32000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # (batch, T, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a48e48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_inp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcos_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msin_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# x is of shape (seqlen, )\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     56\u001b[0m         seqlen \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/_module.py:1189\u001b[0m, in \u001b[0;36mPartial.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the wrapped `self.func`.\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m \n\u001b[1;32m   1179\u001b[0m \u001b[38;5;124;03m    **Arguments:**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03m    The result of the wrapped function.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mTransformer.compute_embeddings\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/nn/_embedding.py:101\u001b[0m, in \u001b[0;36mEmbedding.__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[x]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `jax.vmap` if you would like to index with multiple values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values."
     ]
    }
   ],
   "source": [
    "model(\n",
    "    fake_inp,\n",
    "    cos_freq[fake_pos],\n",
    "    sin_freq[fake_pos],\n",
    "    fake_pos,\n",
    "    fake_mask,\n",
    "    cache_k,\n",
    "    cache_v,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/nn/_embedding.py\u001b[0m(101)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m            raise ValueError(\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m                \u001b[0;34m\"`eqx.nn.Embedding()(x)` should be called with a scalar index `x`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    103 \u001b[0;31m                \u001b[0;34m\"Use `jax.vmap` if you would like to index with multiple values.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/contextlib.py\u001b[0m(81)\u001b[0;36minner\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     79 \u001b[0;31m        \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     80 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 81 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     82 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py\u001b[0m(24)\u001b[0;36mcompute_embeddings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     22 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 24 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0meqx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31m    [... skipped 3 hidden frame(s)]\u001b[0m\n",
      "\n",
      "(1, 5)\n",
      "*** ValueError: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.\n",
      "*** ValueError: `eqx.nn.Embedding()(x)` should be called with a scalar index `x`. Use `jax.vmap` if you would like to index with multiple values.\n",
      "*** jax.errors.UnexpectedTracerError: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type int32[1,5] wrapped in a DynamicJaxprTracer to escape the scope of the transformation.\n",
      "JAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\n",
      "The function being traced when the value leaked was compute_embeddings at /Users/xaviergonzalez/opt/anaconda3/envs/mistral-eqx/lib/python3.12/site-packages/equinox/_jit.py:37 traced for jit.\n",
      "------------------------------\n",
      "The leaked intermediate value was created on line /var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py:53:12 (Transformer.__call__). \n",
      "------------------------------\n",
      "When the value was created, the final 5 stack frames (most recent last) excluding JAX-internal frames were:\n",
      "------------------------------\n",
      "<frozen runpy>:198:11 (_run_module_as_main)\n",
      "<frozen runpy>:88:4 (_run_code)\n",
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/1221483641.py:1 (<module>)\n",
      "/var/folders/tf/ybkfqmld4yb8_yn2xr11sl8m0000gn/T/ipykernel_2338/467368851.py:53:12 (Transformer.__call__)\n",
      "------------------------------\n",
      "\n",
      "To catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223d912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-eqx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
